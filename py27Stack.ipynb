{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "def plot_fe(series, xlabel='', ylabel='', title='', figsize=(13, 10), font_size=14, sort=True):\n",
    "    if sort:\n",
    "        series = series.sort_values(ascending=False)\n",
    "        \n",
    "    plt.figure(figsize=figsize);\n",
    "    sns.set(font_scale=font_size/10.0)\n",
    "    ax = sns.barplot(x=series.values.reshape(1, -1)[0], y=series.index);\n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel, fontsize=font_size)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel, fontsize=font_size)\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=font_size)\n",
    "    plt.show()\n",
    "    \n",
    "# %config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for predicting bookmakers probability\n",
    "def preproc(lcldf, cols):\n",
    "    kefs = pd.read_csv('./data/csgoKefs.csv', sep=';')\n",
    "    kefs['kefs'] = kefs['kefs'].apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "    kefs['teamAkef'] = kefs['kefs'].apply(lambda x: np.median(x.T[0]))\n",
    "    kefs['teamBkef'] = kefs['kefs'].apply(lambda x: np.median(x.T[1]))\n",
    "    kefs['teamAperMarja'] = 1/kefs['teamAkef'].values\n",
    "    kefs['teamBperMarja'] = 1/kefs['teamBkef'].values\n",
    "    kefs['teamAper'] = kefs['teamAperMarja'].values/(kefs['teamAperMarja'].values + kefs['teamBperMarja'].values)\n",
    "    kefs['teamBper'] = kefs['teamBperMarja'].values/(kefs['teamAperMarja'].values + kefs['teamBperMarja'].values)\n",
    "\n",
    "    # kefs['teamAkef'] = kefs['kefs'].apply(lambda x: np.min(x.T[0]))\n",
    "    # kefs['teamBkef'] = kefs['kefs'].apply(lambda x: np.min(x.T[1]))\n",
    "\n",
    "    kefs['teamAkef'] = np.minimum(kefs['teamAkef'].values, [7]*kefs.shape[0])\n",
    "    kefs['teamBkef'] = np.minimum(kefs['teamBkef'].values, [7]*kefs.shape[0])\n",
    "    \n",
    "#     ids = pd.read_csv('matchLinkIds.csv', sep=';')\n",
    "#     newIndex = np.arange(ids.shape[0])\n",
    "#     newIndex[::2] = ids.index.values[:ids.shape[0]//2]\n",
    "#     newIndex[1::2] = ids.index.values[ids.shape[0]//2:]\n",
    "#     ids.loc[ids.index] = ids.loc[newIndex].values\n",
    "#     ids.reset_index(drop=True, inplace=True)\n",
    "#     ids = ids.iloc[int(ids.shape[0]*0.1):]\n",
    "#     ids.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# #     lcldf = pd.read_csv('elo0_1_1000_28RD.csv', sep=';')\n",
    "# #     lcldf.rename(columns={'teamBRelativeForceWeightedNOHistoryW.1':'teamBRelativeForceNOHistorySpecW'}, inplace=True)\n",
    "#     lcldf = pd.merge(lcldf, ids, left_index=True, right_index=True)\n",
    "    lcldf = pd.merge(lcldf, kefs,  how='inner', left_on=['matchlinkId','teamAId', 'teamBId'], right_on = ['matchLinkId','teamAId', 'teamBId'])\n",
    "    print lcldf.shape\n",
    "    lcldf.drop(lcldf[(lcldf['teamAperMarja'] + lcldf['teamBperMarja']-1)<0].index, inplace=True)\n",
    "    lcldf.drop_duplicates(['matchlinkId','teamAId', 'teamBId'], inplace=True)\n",
    "    \n",
    "    columnA = [i.replace('B', 'A') for i in cols + list(kefs.columns) if 'B' in i]\n",
    "    columnB = [i for i in cols + list(kefs.columns) if 'B' in i]\n",
    "    print columnA, columnB\n",
    "    exchangeList = [1]*(len(columnA) + len(columnB))\n",
    "    exchangeList[::2] = columnA\n",
    "    exchangeList[1::2] = columnB\n",
    "    exchangeList1 = [1]*(len(columnA) + len(columnB))\n",
    "    exchangeList1[::2] = columnB\n",
    "    exchangeList1[1::2] = columnA\n",
    "\n",
    "    oversample = lcldf.copy()\n",
    "    oversample[exchangeList] = oversample[exchangeList1]\n",
    "    oversample['mapPicker'] = -1 * oversample['mapPicker'].values\n",
    "    oversample.loc[oversample[oversample['difScore']>=-16].index, ['isWin', 'difScore']] = -1 * oversample.loc[oversample[oversample['difScore']>=-16].index, ['isWin', 'difScore']]\n",
    "    lcldf = pd.concat([lcldf, oversample])\n",
    "    # df.drop_duplicates(inplace=True)\n",
    "    lcldf.reset_index(drop=True, inplace=True)\n",
    "    return lcldf\n",
    "    \n",
    "def kefPrediction(lcldf, cols):\n",
    "    lcldf = preproc(lcldf, cols)\n",
    "    \n",
    "    y_col = 'teamAper'\n",
    "\n",
    "    trX, teX, trY, teY = preproc_data(lcldf, cols, y_col)\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': 21,\n",
    "        'learning_rate': 0.03,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'verbose': 0,\n",
    "        'n_jobs': 2,\n",
    "    }\n",
    "    kefPred = fit_model(params, trX, teX, trY, teY)\n",
    "\n",
    "#     kefPred = XGBRegressor(max_depth=6, n_estimators=200, learning_rate=.06)\n",
    "    \n",
    "#     trX, teX, trY, teY = train_test_split(lcldf[cols].values, lcldf['teamAper'].values, test_size=0.3, stratify=None)\n",
    "#     kefPred.fit(trX, trY)\n",
    "#     pred = kefPred.predict(teX)\n",
    "#     print mean_absolute_error(teY, pred)\n",
    "#     pred = kefPred.predict(lcldf[cols].values)\n",
    "#     print mean_absolute_error(pred, lcldf['teamAper'].values)\n",
    "    return kefPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(ldf, pred_clmns, y_col, test_size=0.2, random_state=523, cond=None):\n",
    "    if cond is None:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(ldf[pred_clmns], ldf[y_col], test_size=test_size, random_state=random_state)\n",
    "    else:\n",
    "        \n",
    "#     if 'alf' in y_col and 'istol' in y_col:\n",
    "#         cond = ldf[y_col]!=0\n",
    "        x_train, x_test, y_train, y_test = train_test_split(ldf[cond][pred_clmns], ldf[cond][y_col], test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        \n",
    "    print 'TRAIN SHAPE:', x_train.shape, 'TEST SHAPE:', x_test.shape\n",
    "    if 'alf' in y_col and 'istol' in y_col:\n",
    "        y_train.replace({-1: 0}, inplace=True)\n",
    "        y_test.replace({-1: 0}, inplace=True)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def fit_model(params, x_train, x_test, y_train, y_test, weight_train=None, weight_test=None, modelname='lgb', cat_clmns=[]):\n",
    "    if modelname=='lgb':\n",
    "        # define lgb train and validation Datasets\n",
    "        d_train = lgb.Dataset(x_train, y_train, weight=weight_train)\n",
    "        d_valid = lgb.Dataset(x_test, y_test, weight=weight_test)\n",
    "\n",
    "        # train model\n",
    "        print '\\nSTART FITTING:'\n",
    "        model = lgb.train(params=params, \n",
    "                        train_set=d_train, \n",
    "                        num_boost_round=5000, \n",
    "                        valid_sets=[d_valid],\n",
    "                        verbose_eval=100, \n",
    "                        early_stopping_rounds=25)\n",
    "        print 'FITTING HAS BEEN ENDED\\n'\n",
    "        \n",
    "        print 'VALIDATION:'\n",
    "        if params['objective']=='binary':\n",
    "            train_pred = model.predict(x_train)\n",
    "            test_pred = model.predict(x_test)\n",
    "\n",
    "            print 'TRAIN ROC_AUC:', round(roc_auc_score(y_train, train_pred), 6), 'ACCURACY:', round(accuracy_score(y_train, np.round(train_pred)), 6)\n",
    "            print 'TEST ROC_AUC:', round(roc_auc_score(y_test, test_pred), 6), 'ACCURACY:', round(accuracy_score(y_test, np.round(test_pred)), 6)\n",
    "            \n",
    "        else:#params['objective']=='regression'\n",
    "            train_pred = model.predict(x_train)\n",
    "            test_pred = model.predict(x_test)\n",
    "\n",
    "            print 'TRAIN MAE:', round(mean_absolute_error(y_train, train_pred), 6), 'MSE:', round(mean_squared_error(y_train, train_pred), 6)\n",
    "            print 'TEST MAE:', round(mean_absolute_error(y_test, test_pred), 6), 'MSE:', round(mean_squared_error(y_test, test_pred), 6)\n",
    "            \n",
    "        return model\n",
    "    \n",
    "    elif modelname=='RandomForest':\n",
    "        objective = params.pop('objective')\n",
    "        if objective == 'binary':\n",
    "            model = RandomForestClassifier(**params)\n",
    "        else:\n",
    "            model = RandomForestRegressor(**params)\n",
    "        \n",
    "        print '\\nSTART FITTING:'\n",
    "        model.fit(x_train, y_train)\n",
    "        print 'FITTING HAS BEEN ENDED\\n'\n",
    "        \n",
    "        print 'VALIDATION:'\n",
    "        if objective == 'binary':\n",
    "            train_pred = model.predict_proba(x_train).T[1]\n",
    "            test_pred = model.predict_proba(x_test).T[1]\n",
    "            \n",
    "            print 'TRAIN ROC_AUC:', round(roc_auc_score(y_train, train_pred), 6), 'ACCURACY:', round(accuracy_score(y_train, np.round(train_pred)), 6)\n",
    "            print 'TEST ROC_AUC:', round(roc_auc_score(y_test, test_pred), 6), 'ACCURACY:', round(accuracy_score(y_test, np.round(test_pred)), 6)\n",
    "        else:\n",
    "            train_pred = model.predict(x_train)\n",
    "            test_pred = model.predict(x_test)\n",
    "\n",
    "            print 'TRAIN MAE:', round(mean_absolute_error(y_train, train_pred), 6), 'MSE:', round(mean_squared_error(y_train, train_pred), 6)\n",
    "            print 'TEST MAE:', round(mean_absolute_error(y_test, test_pred), 6), 'MSE:', round(mean_squared_error(y_test, test_pred), 6)\n",
    "            \n",
    "        return model\n",
    "    \n",
    "    elif modelname=='Linear':\n",
    "        objective = params.pop('objective')\n",
    "        if objective == 'binary':\n",
    "            model = LogisticRegression(**params)\n",
    "        else:\n",
    "            model = LinearRegression(**params)\n",
    "            \n",
    "        #preproccessing\n",
    "        continous_features = [i for i in x_train.columns if i not in cat_clmns]\n",
    "        for cat_col in cat_clmns:\n",
    "            _ = x_train[cat_col].unique()\n",
    "            if _.shape[0]<=2:\n",
    "                continue\n",
    "            for value in _:\n",
    "                x_train['%s_%s'%(cat_col, int(value))] = (x_train[cat_col] == value)*1\n",
    "                x_test['%s_%s'%(cat_col, int(value))] = (x_test[cat_col] == value)*1\n",
    "            x_train.drop(cat_col, axis=1, inplace = True)\n",
    "            x_test.drop(cat_col, axis=1, inplace = True)\n",
    "                \n",
    "        standardScaler = StandardScaler()\n",
    "        x_train[continous_features] = standardScaler.fit_transform(x_train[continous_features].values)\n",
    "        x_test[continous_features] = standardScaler.transform(x_test[continous_features].values)\n",
    "        \n",
    "        print '\\nSTART FITTING:'\n",
    "        model.fit(x_train, y_train)\n",
    "        print 'FITTING HAS BEEN ENDED\\n'\n",
    "        \n",
    "        print 'VALIDATION:'\n",
    "        if objective == 'binary':\n",
    "            train_pred = model.predict_proba(x_train).T[1]\n",
    "            test_pred = model.predict_proba(x_test).T[1]\n",
    "            \n",
    "            print 'TRAIN ROC_AUC:', round(roc_auc_score(y_train, train_pred), 6), 'ACCURACY:', round(accuracy_score(y_train, np.round(train_pred)), 6)\n",
    "            print 'TEST ROC_AUC:', round(roc_auc_score(y_test, test_pred), 6), 'ACCURACY:', round(accuracy_score(y_test, np.round(test_pred)), 6)\n",
    "        else:\n",
    "            train_pred = model.predict(x_train)\n",
    "            test_pred = model.predict(x_test)\n",
    "\n",
    "            print 'TRAIN MAE:', round(mean_absolute_error(y_train, train_pred), 6), 'MSE:', round(mean_squared_error(y_train, train_pred), 6)\n",
    "            print 'TEST MAE:', round(mean_absolute_error(y_test, test_pred), 6), 'MSE:', round(mean_squared_error(y_test, test_pred), 6)\n",
    "            \n",
    "        return model\n",
    "    \n",
    "    elif modelname=='DecisionTree':\n",
    "        objective = params.pop('objective')\n",
    "        if objective == 'binary':\n",
    "            model = DecisionTreeClassifier(**params)\n",
    "        else:\n",
    "            model = DecisionTreeRegressor(**params)\n",
    "        \n",
    "        print '\\nSTART FITTING:'\n",
    "        model.fit(x_train, y_train)\n",
    "        print 'FITTING HAS BEEN ENDED\\n'\n",
    "        \n",
    "        print 'VALIDATION:'\n",
    "        if objective == 'binary':\n",
    "            train_pred = model.predict_proba(x_train).T[1]\n",
    "            test_pred = model.predict_proba(x_test).T[1]\n",
    "            \n",
    "            print 'TRAIN ROC_AUC:', round(roc_auc_score(y_train, train_pred), 6), 'ACCURACY:', round(accuracy_score(y_train, np.round(train_pred)), 6)\n",
    "            print 'TEST ROC_AUC:', round(roc_auc_score(y_test, test_pred), 6), 'ACCURACY:', round(accuracy_score(y_test, np.round(test_pred)), 6)\n",
    "        else:\n",
    "            train_pred = model.predict(x_train)\n",
    "            test_pred = model.predict(x_test)\n",
    "\n",
    "            print 'TRAIN MAE:', round(mean_absolute_error(y_train, train_pred), 6), 'MSE:', round(mean_squared_error(y_train, train_pred), 6)\n",
    "            print 'TEST MAE:', round(mean_absolute_error(y_test, test_pred), 6), 'MSE:', round(mean_squared_error(y_test, test_pred), 6)\n",
    "            \n",
    "        return model\n",
    "    \n",
    "    elif modelname=='xgb':\n",
    "        model = XGBRegressor(**params)\n",
    "        \n",
    "        print '\\nSTART FITTING:'\n",
    "        model.fit(x_train, y_train)\n",
    "        print 'FITTING HAS BEEN ENDED\\n'\n",
    "        \n",
    "        print 'VALIDATION:'\n",
    "        train_pred = model.predict(x_train)\n",
    "        test_pred = model.predict(x_test)\n",
    "\n",
    "        print 'TRAIN MAE:', round(mean_absolute_error(y_train, train_pred), 6), 'MSE:', round(mean_squared_error(y_train, train_pred), 6)\n",
    "        print 'TEST MAE:', round(mean_absolute_error(y_test, test_pred), 6), 'MSE:', round(mean_squared_error(y_test, test_pred), 6)\n",
    "            \n",
    "        return model\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The next cells include prediction the winner in pistol rounds and some other predictions but it almost doesn't make any benefit for the final winner prediction model. And this part is quite computationally and time consuming. So i advise you to skip it up to multiple empty cells . But i decided that i would not delete this part for someone finding this interesting to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define helper functions that let us to estimate average probabilities of winning or loosing for a specific team IN PISTOL ROUNDS based on specific time period (28 days by default). It also includes estimation of the number of winning and loosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pistolhf1(tmp, mval, cl_cond, cl, days, weighted): # pistol helper function for pistolCalculationLocal function\n",
    "    \n",
    "    if tmp.shape[0]==0:\n",
    "        return [-0.5, -0.5, 0, 0]\n",
    "    else:\n",
    "        if weighted:\n",
    "            ret_list = [-0.5, -0.5, 0, 0]\n",
    "            \n",
    "            cond = tmp[cl_cond]==1\n",
    "            if cond.any():\n",
    "                trr = ((tmp[cond]['date']-mval).dt.days/float(days)).values# .apply(lambda lcl: 0.001 if (lcl-mval).days==0 else (lcl-mval).days/float(days))\n",
    "                trr[trr==0] = 0.001\n",
    "                ret_list[0] = (trr*tmp[cond][cl]).sum()/trr.sum()\n",
    "                ret_list[2] = cond.sum()\n",
    "            \n",
    "            cond = tmp[cl_cond]==0\n",
    "            if cond.any():\n",
    "                trr = ((tmp[cond]['date']-mval).dt.days/float(days)).values# .apply(lambda lcl: 0.001 if (lcl-mval).days==0 else (lcl-mval).days/float(days))\n",
    "                trr[trr==0] = 0.001\n",
    "                ret_list[1] = (trr*tmp[cond][cl]).sum()/trr.sum()\n",
    "                ret_list[3] = cond.sum()\n",
    "            \n",
    "            return ret_list\n",
    "        else:\n",
    "            ret_list = [-0.5, -0.5, 0, 0]\n",
    "            \n",
    "            cond = tmp[cl_cond]==1\n",
    "            if cond.any():\n",
    "                ret_list[0] = tmp[cond][cl].mean()\n",
    "                ret_list[2] = cond.sum()\n",
    "                \n",
    "            cond = tmp[cl_cond]==0\n",
    "            if cond.any():\n",
    "                ret_list[1] = tmp[cond][cl].mean()\n",
    "                ret_list[3] = cond.sum()\n",
    "                \n",
    "            return ret_list\n",
    "        \n",
    "        \n",
    "def pistolCalculationLocal(dats, ids, data, cl, cl_cond, days, weighted=False):#tmp = [['teamId', 'date']]\n",
    "    lastDats = dats - np.timedelta64(days, 'D')\n",
    "    ttt = (data['teamAId'].values==ids.values.reshape((ids.shape[0], 1))) & (data['date'].values>=lastDats.values.reshape((ids.shape[0], 1))) & (data['date'].values<dats.values.reshape((ids.shape[0], 1))) & (~np.isnan(data[cl].values))\n",
    "    ret = np.array(map(lambda mask, y: pistolhf1(data.loc[mask], y, cl_cond, cl, days, weighted), ttt, lastDats.values))\n",
    "    return ret.T\n",
    "    \n",
    "def pistolHistoryCalculation(newMainDf, data, days, iterateClmns):\n",
    "    \n",
    "    beforeInd = np.arange(newMainDf.shape[0]/2)\n",
    "    afterInd = np.arange(newMainDf.shape[0]/2, newMainDf.shape[0])\n",
    "    \n",
    "    for clmn in iterateClmns:\n",
    "        print clmn\n",
    "#        print dt.datetime.today()#, clmn[2]\n",
    "    \n",
    "        tm = time.time()\n",
    "#        tm = time.time()\n",
    "        tmp = np.concatenate(map(lambda ind: pistolCalculationLocal(newMainDf.loc[ind, 'date'], newMainDf.loc[ind, 'teamAId'], data[['teamAId', 'date', clmn[1], clmn[2]]], clmn[1], clmn[2], days, weighted=clmn[3]), np.array_split(newMainDf.index.values, 1000) ), axis=1)#.reshape((1, indA.shape[0]))\n",
    "#        print time.time() - tm\n",
    "        \n",
    "        replaceClmn = clmn[0].replace('A', 'B')\n",
    "        lclColumns = ['Win', 'Loose', 'WinCount', 'LooseCount']\n",
    "        for ind, lclclmn in enumerate(lclColumns):\n",
    "            newMainDf[clmn[0]+lclclmn] = tmp[ind]\n",
    "            newMainDf[replaceClmn+lclclmn] = 0 if ind//2 else -0.5\n",
    "            newMainDf.loc[beforeInd, replaceClmn+lclclmn] = newMainDf.loc[afterInd, clmn[0]+lclclmn].values\n",
    "            newMainDf.loc[afterInd, replaceClmn+lclclmn] = newMainDf.loc[beforeInd, clmn[0]+lclclmn].values\n",
    "            if ind%2:# ==1\n",
    "                newMainDf[clmn[0]+lclColumns[ind-1]+lclColumns[ind]+'Dif'] = newMainDf[clmn[0]+lclColumns[ind-1]].values - newMainDf[clmn[0]+lclColumns[ind]].values\n",
    "                newMainDf.loc[beforeInd, replaceClmn+lclColumns[ind-1]+lclColumns[ind]+'Dif'] = newMainDf.loc[afterInd, clmn[0]+lclColumns[ind-1]+lclColumns[ind]+'Dif'].values\n",
    "                newMainDf.loc[afterInd, replaceClmn+lclColumns[ind-1]+lclColumns[ind]+'Dif'] = newMainDf.loc[beforeInd, clmn[0]+lclColumns[ind-1]+lclColumns[ind]+'Dif'].values\n",
    "\n",
    "        \n",
    "        print time.time() - tm\n",
    "    return newMainDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define helper functions that let us to estimate average probabilities of winning or loosing for a specific team WITH SPECIFIC TOTAL ROUND PURCHASE (< 5000; 5000-10000; 10000-15000; 15000-20000; > 20000 dollars) based on specific time period (28 days by default). It also includes estimation of the number of winning and loosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cathf1(tmp, mval, cl, days, weighted):\n",
    "    if tmp.shape[0]==0:\n",
    "        return -0.5\n",
    "    else:\n",
    "        if weighted:\n",
    "            trr = ((tmp['date']-mval).dt.days/float(days)).values# .apply(lambda lcl: 0.001 if (lcl-mval).days==0 else (lcl-mval).days/float(days))\n",
    "            trr[trr==0] = 0.001\n",
    "            trr = trr * tmp.iloc[:, -1]\n",
    "            ret_val = (trr*tmp[cl]).sum()/trr.sum()\n",
    "            \n",
    "        else:\n",
    "            ret_val = (tmp.iloc[:, -1] * tmp[cl]).sum()/float(tmp.iloc[:, -1].sum())\n",
    "                \n",
    "        return ret_val\n",
    "        \n",
    "        \n",
    "def catCalculationLocal(dats, ids, data, cl, days, weighted=False):#tmp = [['teamId', 'date']]\n",
    "    lastDats = dats - np.timedelta64(days, 'D')\n",
    "    ttt = (data['teamAId'].values==ids.values.reshape((ids.shape[0], 1))) & (data['date'].values>=lastDats.values.reshape((ids.shape[0], 1))) & (data['date'].values<dats.values.reshape((ids.shape[0], 1))) & (~np.isnan(data[cl].values))\n",
    "    ret = np.array(map(lambda mask, y: cathf1(data.loc[mask], y, cl, days, weighted), ttt, lastDats.values))\n",
    "    return ret\n",
    "    \n",
    "def catHistoryCalculation(newMainDf, days, iterateClmns):\n",
    "\n",
    "    beforeInd = np.arange(newMainDf.shape[0]/2)\n",
    "    afterInd = np.arange(newMainDf.shape[0]/2, newMainDf.shape[0])\n",
    "    \n",
    "    for clmn in iterateClmns:\n",
    "        print clmn\n",
    "#        print dt.datetime.today()#, clmn[2]\n",
    "    \n",
    "        tm = time.time()\n",
    "#         tmp = newMainDf\n",
    "#        tm = time.time()\n",
    "        tmp = np.concatenate(map(lambda ind: catCalculationLocal(newMainDf.loc[ind, 'date'], newMainDf.loc[ind, 'teamAId'], newMainDf.loc[newMainDf[clmn[1]]>=0, ['teamAId', 'date', clmn[1], clmn[2]]], clmn[1], days, weighted=clmn[3]), np.array_split(newMainDf.index.values, 1000) ))#.reshape((1, indA.shape[0]))\n",
    "#         tmp = np.concatenate(map(lambda ind: pistolCalculationLocal(tmp.loc[ind, 'date'], tmp.loc[ind, 'teamAId'], data[['teamAId', 'date', clmn[1], clmn[2]]], clmn[1], clmn[2], days, weighted=clmn[3]), np.array_split(tmp.index.values, 1000) ), axis=1)#.reshape((1, indA.shape[0]))\n",
    "#        print time.time() - tm\n",
    "\n",
    "        newMainDf[clmn[0]] = tmp\n",
    "#         assert False\n",
    "        \n",
    "        replaceClmn = clmn[0].replace('A', 'B')\n",
    "        newMainDf[replaceClmn] = -0.5\n",
    "        newMainDf.loc[beforeInd, replaceClmn] = newMainDf.loc[afterInd, clmn[0]].values\n",
    "        newMainDf.loc[afterInd, replaceClmn] = newMainDf.loc[beforeInd, clmn[0]].values\n",
    "        \n",
    "        print time.time() - tm\n",
    "    return newMainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teamA_half_0_cat5VScat4_played\n",
      "teamA_cat3_played\n",
      "teamA_half_0_cat3_played\n",
      "teamA_cat5VScat0_played\n",
      "teamA_half_1_cat5VScat1_played\n",
      "teamA_half_0_cat0_played\n",
      "teamA_half_1_cat5VScat4_played\n",
      "teamA_cat5VScat2_played\n",
      "teamA_cat4_played\n",
      "teamA_cat2_played\n",
      "teamA_half_1_cat5VScat0_played\n",
      "teamA_half_1_cat3_played\n",
      "teamA_half_1_cat5VScat2_played\n",
      "teamA_half_0_cat1_played\n",
      "teamA_half_0_cat5VScat1_played\n",
      "teamA_cat0_played\n",
      "teamA_half_0_cat5VScat0_played\n",
      "teamA_cat1_played\n",
      "teamA_half_1_cat0_played\n",
      "teamA_half_1_cat5VScat3_played\n",
      "teamA_half_1_cat2_played\n",
      "teamA_half_0_cat4_played\n",
      "teamA_half_1_cat1_played\n",
      "teamA_cat5VScat1_played\n",
      "teamA_half_0_cat5VScat3_played\n",
      "teamA_half_0_cat5VScat2_played\n",
      "teamA_half_1_cat4_played\n",
      "teamA_half_0_cat2_played\n",
      "teamA_cat5VScat3_played\n",
      "teamA_cat5VScat4_played\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    if 'played' in i and 'A' in i and 'pred' not in i:\n",
    "        print i\n",
    "        i = '_'.join(i.split('_')[:-1])\n",
    "#         df[i+'_relative'] = -0.5\n",
    "#         df.loc[df[i+'_played']>0, i+'_relative'] = df.loc[df[i+'_played']>0, i+'_win'] / df.loc[df[i+'_played']>0, i+'_played']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN CALCULATIONS IN ONE CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstHalfPistolPrediction(df, pred_clmns, plot=False):\n",
    "    df['teamAPistol_half_0_pred'] = -1\n",
    "\n",
    "    y_col = 'teamAPistol_half_0'\n",
    "    cond = df[y_col]!=0\n",
    "    x_train, x_test, y_train, y_test = preproc_data(df, pred_clmns, y_col, cond=cond)\n",
    "\n",
    "    params = {\n",
    "            'objective' :'binary',\n",
    "            'learning_rate' : 0.02,\n",
    "            'num_leaves' : 40,\n",
    "            'max_bin': 130,\n",
    "            'max_depth': 4,\n",
    "            'feature_fraction': 0.64, \n",
    "            'bagging_fraction': 0.8, \n",
    "            'bagging_freq':1,\n",
    "            'boosting_type' : 'gbdt',\n",
    "            'metric': 'binary_logloss'\n",
    "    }\n",
    "    model = fit_model(params, x_train, x_test, y_train, y_test)\n",
    "\n",
    "    # prediction\n",
    "    cond = df[y_col]!=0\n",
    "    df.loc[cond, 'teamAPistol_half_0_pred'] = model.predict(df.loc[cond, pred_clmns])\n",
    "\n",
    "    # plot feature_importance\n",
    "    if plot:\n",
    "        fe = pd.Series(model.feature_importance(), index=pred_clmns)\n",
    "        print '\\nFEATURE_IMPORTANCE: \\n', fe\n",
    "        plot_fe(fe)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def secondHalfPistolPrediction(df, pred_clmns, plot=False):\n",
    "    df['teamAPistol_half_1_pred'] = -1\n",
    "\n",
    "    y_col = 'teamAPistol_half_1'\n",
    "    cond = df[y_col]!=0\n",
    "    x_train, x_test, y_train, y_test = preproc_data(df, pred_clmns, y_col, cond=cond)\n",
    "\n",
    "    params = {\n",
    "            'objective' :'binary',\n",
    "            'learning_rate' : 0.02,\n",
    "            'num_leaves' : 50,\n",
    "            'max_bin': 130,\n",
    "            'max_depth': 3,\n",
    "            'feature_fraction': 0.64, \n",
    "            'bagging_fraction': 0.8, \n",
    "            'bagging_freq':1,\n",
    "            'boosting_type' : 'gbdt',\n",
    "            'metric': 'binary_logloss'\n",
    "    }\n",
    "    model = fit_model(params, x_train, x_test, y_train, y_test)\n",
    "\n",
    "    # prediction\n",
    "    cond = df[y_col]!=0\n",
    "    df.loc[cond, 'teamAPistol_half_1_pred'] = model.predict(df.loc[cond, pred_clmns])\n",
    "\n",
    "    if plot:\n",
    "        # plot feature_importance\n",
    "        fe = pd.Series(model.feature_importance(), index=pred_clmns)\n",
    "        print '\\nFEATURE_IMPORTANCE: \\n', fe\n",
    "        plot_fe(fe)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def pistolPrediction(df, common_pistol, pred_clmns, plot=False):\n",
    "\n",
    "    y_col = 'teamAPistol'\n",
    "    x_train, x_test, y_train, y_test = preproc_data(common_pistol, pred_clmns, y_col)\n",
    "\n",
    "    params = {\n",
    "            'objective' :'binary',\n",
    "            'learning_rate' : 0.02,\n",
    "            'num_leaves' : 40,\n",
    "            'max_bin': 130,\n",
    "            'max_depth': 4,\n",
    "            'feature_fraction': 0.64, \n",
    "            'bagging_fraction': 0.8, \n",
    "            'bagging_freq':1,\n",
    "            'boosting_type' : 'gbdt',\n",
    "            'metric': 'binary_logloss'\n",
    "    }\n",
    "    model = fit_model(params, x_train, x_test, y_train, y_test)\n",
    "\n",
    "    # predictions\n",
    "    if 'teamAPistol_pred_CT' in df.columns:\n",
    "        df.drop(['teamAPistol_pred_CT', 'teamAPistol_pred_T'], axis=1, inplace=True)\n",
    "    if 'teamAPistol_pred_CT' not in df.columns:\n",
    "    #     df['teamAPistol_pred_CT'] = -1\n",
    "    #     df['teamAPistol_pred_T'] = -1\n",
    "        common_pistol['teamAPistol_pred_CT'] = -1\n",
    "        common_pistol['teamAPistol_pred_T'] = -1\n",
    "        common_pistol.loc[common_pistol['teamAHalf']==1, 'teamAPistol_pred_CT'] = model.predict(common_pistol.loc[common_pistol['teamAHalf']==1, pred_clmns])\n",
    "        common_pistol.loc[common_pistol['teamAHalf']==0, 'teamAPistol_pred_T'] = model.predict(common_pistol.loc[common_pistol['teamAHalf']==0, pred_clmns])\n",
    "\n",
    "        df = pd.merge(df, common_pistol.loc[common_pistol['teamAHalf']==0, ['matchlinkId', 'teamAId', 'teamBId', 'map', 'teamAPistol_pred_T']], how='left', on=['matchlinkId', 'teamAId', 'teamBId', 'map'])\n",
    "        df = pd.merge(df, common_pistol.loc[common_pistol['teamAHalf']==1, ['matchlinkId', 'teamAId', 'teamBId', 'map', 'teamAPistol_pred_CT']], how='left', on=['matchlinkId', 'teamAId', 'teamBId', 'map'])\n",
    "        df[['teamAPistol_pred_T', 'teamAPistol_pred_CT']] = df[['teamAPistol_pred_T', 'teamAPistol_pred_CT']].fillna(-1)\n",
    "\n",
    "    # plot feature_importance\n",
    "    if plot:\n",
    "        fe = pd.Series(model.feature_importance(), index=pred_clmns)\n",
    "        print '\\nFEATURE_IMPORTANCE: \\n', fe\n",
    "        plot_fe(fe)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Predicting 'cat_played' fot matches where 'cat_played' is absent. Predicting based on difScore\n",
    "def catPlayedApostorioPrediction(df, pred_clmns, i, plot=False):\n",
    "\n",
    "    y_col = i + '_played'\n",
    "    cond = df[y_col]>0\n",
    "\n",
    "    x_train, x_test, y_train, y_test = preproc_data(df, pred_clmns, y_col, cond=cond)\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': 10,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        'n_jobs': 2,\n",
    "    }\n",
    "    model = fit_model(params, x_train, x_test, y_train, y_test)\n",
    "\n",
    "    #prediction\n",
    "    df[y_col+'_pred'] = model.predict(df[pred_clmns])\n",
    "    \n",
    "    # plot feature_importance\n",
    "    if plot:\n",
    "        fe = pd.Series(model.feature_importance(), index=pred_clmns)\n",
    "        print '\\nFEATURE_IMPORTANCE: \\n', fe\n",
    "        plot_fe(fe)\n",
    "        \n",
    "    return df\n",
    "\n",
    "# Predicting 'cat_relative' fot matches where 'cat_relative'>=0. Predicting based on difScore and teamA_cat4_played_pred\n",
    "def catRelativeApostorioPrediction(df, pred_clmns, i, plot=False):\n",
    "    \n",
    "    y_col = i + '_relative'\n",
    "    cond = df[y_col]>=0\n",
    "\n",
    "    x_train, x_test, y_train, y_test = preproc_data(df, pred_clmns, y_col, cond=cond)\n",
    "    W_train = df.loc[x_train.index, i + '_played'].values\n",
    "    W_test = df.loc[x_test.index, i + '_played'].values\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': 21,\n",
    "        'learning_rate': 0.03,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'verbose': 0,\n",
    "        'n_jobs': 2,\n",
    "    }\n",
    "    model = fit_model(params, x_train, x_test, y_train, y_test, W_train, W_test)\n",
    "\n",
    "    # prediction\n",
    "    df[y_col+'_pred'] = np.minimum(1, np.maximum(0, model.predict(df[pred_clmns])))\n",
    "    df.loc[cond, y_col+'_pred'] = df.loc[cond, y_col].values\n",
    "#     df[y_col+'_pred'] = np.minimum(1, np.maximum(0, model.predict(df[pred_clmns])))\n",
    "#     df.loc[df[y_col]>=0, y_col+'_pred'] = df.loc[df[y_col]>=0, y_col].values\n",
    "\n",
    "    if plot:\n",
    "        # plot feature_importance\n",
    "        fe = pd.Series(model.feature_importance(), index=pred_clmns)\n",
    "        print '\\nFEATURE_IMPORTANCE: \\n', fe\n",
    "        plot_fe(fe)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Predicting 'cat_played' fot matches where 'cat_played' is absent. Predicting based on difScore\n",
    "def catPlayedPriorioPrediction(df, pred_clmns, i, plot=False):\n",
    "\n",
    "    y_col = i + '_played'\n",
    "    cond = df[y_col]>0\n",
    "\n",
    "    x_train, x_test, y_train, y_test = preproc_data(df, pred_clmns, y_col, cond=cond)\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': 10,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        'n_jobs': 2,\n",
    "    }\n",
    "    model = fit_model(params, x_train, x_test, y_train, y_test)\n",
    "\n",
    "    #prediction\n",
    "    df[y_col+'_pred_prio'] = model.predict(df[pred_clmns])\n",
    "    \n",
    "    # plot feature_importance\n",
    "    if plot:\n",
    "        fe = pd.Series(model.feature_importance(), index=pred_clmns)\n",
    "        print '\\nFEATURE_IMPORTANCE: \\n', fe\n",
    "        plot_fe(fe)\n",
    "        \n",
    "    return df\n",
    "\n",
    "# Predicting 'cat_relative' fot matches where 'cat_relative'>=0. Predicting based on difScore and teamA_cat4_played_pred\n",
    "def catRelativePriorioPrediction(df, pred_clmns, i, plot=False):\n",
    "    \n",
    "    y_col = i + '_relative'\n",
    "    cond = df[y_col]>=0\n",
    "\n",
    "    x_train, x_test, y_train, y_test = preproc_data(df, pred_clmns, y_col, cond=cond)\n",
    "    W_train = df.loc[x_train.index, i + '_played'].values\n",
    "    W_test = df.loc[x_test.index, i + '_played'].values\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': 21,\n",
    "        'learning_rate': 0.03,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'verbose': 0,\n",
    "        'n_jobs': 2,\n",
    "    }\n",
    "    model = fit_model(params, x_train, x_test, y_train, y_test, W_train, W_test)\n",
    "\n",
    "    # prediction\n",
    "    df[y_col+'_pred_prio'] = np.minimum(1, np.maximum(0, model.predict(df[pred_clmns])))\n",
    "#     df[y_col+'_pred'] = np.minimum(1, np.maximum(0, model.predict(df[pred_clmns])))\n",
    "#     df.loc[df[y_col]>=0, y_col+'_pred'] = df.loc[df[y_col]>=0, y_col].values\n",
    "\n",
    "    if plot:\n",
    "        # plot feature_importance\n",
    "        fe = pd.Series(model.feature_importance(), index=pred_clmns)\n",
    "        print '\\nFEATURE_IMPORTANCE: \\n', fe\n",
    "        plot_fe(fe)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95044, 0)\n",
      "!!!!!!!!!!! PREFIX: HLTV\n",
      "(105604, 89) (105604, 200)\n",
      "189\n",
      "SHAPE (105604, 281)\n",
      "TRAIN SHAPE: (76532, 19) TEST SHAPE: (19134, 19)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.653911\n",
      "[100]\tvalid_0's binary_logloss: 0.641437\n",
      "[150]\tvalid_0's binary_logloss: 0.637411\n",
      "[200]\tvalid_0's binary_logloss: 0.635828\n",
      "[250]\tvalid_0's binary_logloss: 0.635352\n",
      "[300]\tvalid_0's binary_logloss: 0.635202\n",
      "Early stopping, best iteration is:\n",
      "[298]\tvalid_0's binary_logloss: 0.63519\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.704866 ACCURACY: 0.650238\n",
      "TEST ROC_AUC: 0.692028 ACCURACY: 0.642312\n",
      "TRAIN SHAPE: (76532, 22) TEST SHAPE: (19134, 22)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.686806\n",
      "[100]\tvalid_0's binary_logloss: 0.685029\n",
      "[150]\tvalid_0's binary_logloss: 0.684178\n",
      "[200]\tvalid_0's binary_logloss: 0.683664\n",
      "[250]\tvalid_0's binary_logloss: 0.683461\n",
      "[300]\tvalid_0's binary_logloss: 0.683343\n",
      "[350]\tvalid_0's binary_logloss: 0.683198\n",
      "[400]\tvalid_0's binary_logloss: 0.683153\n",
      "Early stopping, best iteration is:\n",
      "[386]\tvalid_0's binary_logloss: 0.683148\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.593416 ACCURACY: 0.564195\n",
      "TEST ROC_AUC: 0.574827 ACCURACY: 0.551584\n",
      "(191332, 26)\n",
      "1    95666\n",
      "0    95666\n",
      "Name: teamAPistol, dtype: int64\n",
      "('teamAPistolHistory', 'teamAPistol_pred', 'teamAPistol', True)\n",
      "581.226000071\n",
      "TRAIN SHAPE: (153065, 25) TEST SHAPE: (38267, 25)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.67558\n",
      "[100]\tvalid_0's binary_logloss: 0.66878\n",
      "[150]\tvalid_0's binary_logloss: 0.666535\n",
      "[200]\tvalid_0's binary_logloss: 0.665577\n",
      "[250]\tvalid_0's binary_logloss: 0.665119\n",
      "[300]\tvalid_0's binary_logloss: 0.664978\n",
      "[350]\tvalid_0's binary_logloss: 0.664885\n",
      "[400]\tvalid_0's binary_logloss: 0.664832\n",
      "[450]\tvalid_0's binary_logloss: 0.664774\n",
      "Early stopping, best iteration is:\n",
      "[443]\tvalid_0's binary_logloss: 0.664768\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.645959 ACCURACY: 0.601529\n",
      "TEST ROC_AUC: 0.631817 ACCURACY: 0.592782\n",
      "teamA_half_0_cat5VScat4_played\n",
      "teamA_cat3_played\n",
      "teamA_half_0_cat3_played\n",
      "teamA_cat5VScat0_played\n",
      "teamA_half_1_cat5VScat1_played\n",
      "teamA_half_0_cat0_played\n",
      "teamA_half_1_cat5VScat4_played\n",
      "teamA_cat5VScat2_played\n",
      "teamA_cat4_played\n",
      "teamA_cat2_played\n",
      "teamA_half_1_cat5VScat0_played\n",
      "teamA_half_1_cat3_played\n",
      "teamA_half_1_cat5VScat2_played\n",
      "teamA_half_0_cat1_played\n",
      "teamA_half_0_cat5VScat1_played\n",
      "teamA_cat0_played\n",
      "teamA_half_0_cat5VScat0_played\n",
      "teamA_cat1_played\n",
      "teamA_half_1_cat0_played\n",
      "teamA_half_1_cat5VScat3_played\n",
      "teamA_half_1_cat2_played\n",
      "teamA_half_0_cat4_played\n",
      "teamA_half_1_cat1_played\n",
      "teamA_cat5VScat1_played\n",
      "teamA_half_0_cat5VScat3_played\n",
      "teamA_half_0_cat5VScat2_played\n",
      "teamA_half_1_cat4_played\n",
      "teamA_half_0_cat2_played\n",
      "teamA_cat5VScat3_played\n",
      "teamA_cat5VScat4_played\n",
      "teamA_cat3\n",
      "TRAIN SHAPE: (40680, 20) TEST SHAPE: (10170, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 1.5719\tvalid_0's l1: 1.00124\n",
      "[100]\tvalid_0's l2: 1.56396\tvalid_0's l1: 0.996517\n",
      "[150]\tvalid_0's l2: 1.56265\tvalid_0's l1: 0.996316\n",
      "[200]\tvalid_0's l2: 1.56104\tvalid_0's l1: 0.995411\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's l2: 1.56129\tvalid_0's l1: 0.995254\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.986085 MSE: 1.529946\n",
      "TEST MAE: 0.995254 MSE: 1.561294\n",
      "TRAIN SHAPE: (40680, 21) TEST SHAPE: (10170, 21)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.081764\tvalid_0's l1: 0.231853\n",
      "[100]\tvalid_0's l2: 0.0794974\tvalid_0's l1: 0.225632\n",
      "[150]\tvalid_0's l2: 0.0792429\tvalid_0's l1: 0.224285\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's l2: 0.0792202\tvalid_0's l1: 0.224094\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.2615 MSE: 0.103578\n",
      "TEST MAE: 0.266496 MSE: 0.10731\n",
      "teamA_cat5VScat0\n",
      "TRAIN SHAPE: (38726, 20) TEST SHAPE: (9682, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 1.05895\tvalid_0's l1: 0.833649\n",
      "[100]\tvalid_0's l2: 1.05447\tvalid_0's l1: 0.826011\n",
      "[150]\tvalid_0's l2: 1.05369\tvalid_0's l1: 0.823989\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's l2: 1.05344\tvalid_0's l1: 0.824095\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.815391 MSE: 1.026471\n",
      "TEST MAE: 0.824095 MSE: 1.053437\n",
      "TRAIN SHAPE: (38726, 21) TEST SHAPE: (9682, 21)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.0230303\tvalid_0's l1: 0.0938121\n",
      "[100]\tvalid_0's l2: 0.022959\tvalid_0's l1: 0.0932536\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's l2: 0.022956\tvalid_0's l1: 0.0932073\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.101544 MSE: 0.030003\n",
      "TEST MAE: 0.102876 MSE: 0.030949\n",
      "teamA_cat5VScat2\n",
      "TRAIN SHAPE: (24816, 20) TEST SHAPE: (6205, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.621816\tvalid_0's l1: 0.632671\n",
      "[100]\tvalid_0's l2: 0.620583\tvalid_0's l1: 0.628933\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's l2: 0.620431\tvalid_0's l1: 0.62906\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.6112 MSE: 0.578419\n",
      "TEST MAE: 0.62906 MSE: 0.620431\n",
      "TRAIN SHAPE: (24816, 21) TEST SHAPE: (6205, 21)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.120529\tvalid_0's l1: 0.294787\n",
      "[100]\tvalid_0's l2: 0.119778\tvalid_0's l1: 0.291155\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's l2: 0.119732\tvalid_0's l1: 0.290898\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.329421 MSE: 0.145128\n",
      "TEST MAE: 0.331432 MSE: 0.148024\n",
      "teamA_cat4\n",
      "TRAIN SHAPE: (46420, 20) TEST SHAPE: (11606, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 2.70028\tvalid_0's l1: 1.291\n",
      "[100]\tvalid_0's l2: 2.44314\tvalid_0's l1: 1.23473\n",
      "[150]\tvalid_0's l2: 2.41287\tvalid_0's l1: 1.22858\n",
      "[200]\tvalid_0's l2: 2.40754\tvalid_0's l1: 1.2277\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's l2: 2.4062\tvalid_0's l1: 1.2275\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 1.204974 MSE: 2.334852\n",
      "TEST MAE: 1.227504 MSE: 2.406197\n",
      "TRAIN SHAPE: (46420, 21) TEST SHAPE: (11606, 21)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.00690368\tvalid_0's l1: 0.0647424\n",
      "[100]\tvalid_0's l2: 0.00550258\tvalid_0's l1: 0.0577757\n",
      "[150]\tvalid_0's l2: 0.00534793\tvalid_0's l1: 0.0570619\n",
      "[200]\tvalid_0's l2: 0.00531919\tvalid_0's l1: 0.0569418\n",
      "[250]\tvalid_0's l2: 0.00530944\tvalid_0's l1: 0.0568982\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's l2: 0.00530939\tvalid_0's l1: 0.056897\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.059856 MSE: 0.005866\n",
      "TEST MAE: 0.059802 MSE: 0.005942\n",
      "teamA_cat2\n",
      "TRAIN SHAPE: (27180, 20) TEST SHAPE: (6796, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.700941\tvalid_0's l1: 0.667101\n",
      "[100]\tvalid_0's l2: 0.700572\tvalid_0's l1: 0.663297\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's l2: 0.700075\tvalid_0's l1: 0.664268\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.661956 MSE: 0.700603\n",
      "TEST MAE: 0.664268 MSE: 0.700075\n",
      "TRAIN SHAPE: (27180, 21) TEST SHAPE: (6796, 21)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.118359\tvalid_0's l1: 0.293703\n",
      "[100]\tvalid_0's l2: 0.117273\tvalid_0's l1: 0.2892\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's l2: 0.117229\tvalid_0's l1: 0.288919\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.330424 MSE: 0.145042\n",
      "TEST MAE: 0.333115 MSE: 0.147063\n",
      "teamA_cat0\n",
      "TRAIN SHAPE: (41277, 20) TEST SHAPE: (10320, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 1.23708\tvalid_0's l1: 0.872029\n",
      "[100]\tvalid_0's l2: 1.22564\tvalid_0's l1: 0.867089\n",
      "[150]\tvalid_0's l2: 1.2234\tvalid_0's l1: 0.866595\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's l2: 1.22319\tvalid_0's l1: 0.866508\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.847173 MSE: 1.169978\n",
      "TEST MAE: 0.866508 MSE: 1.223186\n",
      "TRAIN SHAPE: (41277, 21) TEST SHAPE: (10320, 21)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's l2: 0.0191358\tvalid_0's l1: 0.089394\n",
      "[100]\tvalid_0's l2: 0.0190651\tvalid_0's l1: 0.0887239\n",
      "[150]\tvalid_0's l2: 0.0190584\tvalid_0's l1: 0.0884765\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's l2: 0.0190548\tvalid_0's l1: 0.0884878\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.100752 MSE: 0.027313\n",
      "TEST MAE: 0.099641 MSE: 0.026528\n",
      "teamA_cat1\n",
      "TRAIN SHAPE: (39216, 20) TEST SHAPE: (9805, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 1.19322\tvalid_0's l1: 0.880773\n",
      "[100]\tvalid_0's l2: 1.18479\tvalid_0's l1: 0.873693\n",
      "[150]\tvalid_0's l2: 1.18278\tvalid_0's l1: 0.872105\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's l2: 1.18257\tvalid_0's l1: 0.871923\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.862862 MSE: 1.164597\n",
      "TEST MAE: 0.871923 MSE: 1.182568\n",
      "TRAIN SHAPE: (39216, 21) TEST SHAPE: (9805, 21)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.0637488\tvalid_0's l1: 0.206643\n",
      "[100]\tvalid_0's l2: 0.0631182\tvalid_0's l1: 0.203833\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's l2: 0.0631046\tvalid_0's l1: 0.203649\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.237645 MSE: 0.084852\n",
      "TEST MAE: 0.241398 MSE: 0.087819\n",
      "teamA_cat5VScat1\n",
      "TRAIN SHAPE: (34488, 20) TEST SHAPE: (8623, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.927224\tvalid_0's l1: 0.761321\n",
      "[100]\tvalid_0's l2: 0.926173\tvalid_0's l1: 0.760606\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's l2: 0.926093\tvalid_0's l1: 0.76023\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.75822 MSE: 0.938632\n",
      "TEST MAE: 0.76023 MSE: 0.926093\n",
      "TRAIN SHAPE: (34488, 21) TEST SHAPE: (8623, 21)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.0737476\tvalid_0's l1: 0.22045\n",
      "[100]\tvalid_0's l2: 0.0733651\tvalid_0's l1: 0.217948\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's l2: 0.0733306\tvalid_0's l1: 0.217794\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.245985 MSE: 0.094816\n",
      "TEST MAE: 0.250522 MSE: 0.09815\n",
      "teamA_cat5VScat3\n",
      "TRAIN SHAPE: (29107, 20) TEST SHAPE: (7277, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.763392\tvalid_0's l1: 0.691059\n",
      "[100]\tvalid_0's l2: 0.761634\tvalid_0's l1: 0.687099\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's l2: 0.761618\tvalid_0's l1: 0.68709\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.686104 MSE: 0.766469\n",
      "TEST MAE: 0.68709 MSE: 0.761618\n",
      "TRAIN SHAPE: (29107, 21) TEST SHAPE: (7277, 21)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.124419\tvalid_0's l1: 0.298697\n",
      "[100]\tvalid_0's l2: 0.123284\tvalid_0's l1: 0.294738\n",
      "[150]\tvalid_0's l2: 0.123232\tvalid_0's l1: 0.293934\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's l2: 0.123177\tvalid_0's l1: 0.294\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.343273 MSE: 0.153543\n",
      "TEST MAE: 0.344263 MSE: 0.155808\n",
      "teamA_cat5VScat4\n",
      "TRAIN SHAPE: (46420, 20) TEST SHAPE: (11606, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 3.22025\tvalid_0's l1: 1.42434\n",
      "[100]\tvalid_0's l2: 3.01999\tvalid_0's l1: 1.37943\n",
      "[150]\tvalid_0's l2: 2.99939\tvalid_0's l1: 1.37512\n",
      "[200]\tvalid_0's l2: 2.99453\tvalid_0's l1: 1.37467\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid_0's l2: 2.99398\tvalid_0's l1: 1.37433\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 1.352243 MSE: 2.923276\n",
      "TEST MAE: 1.374335 MSE: 2.993982\n",
      "TRAIN SHAPE: (46420, 21) TEST SHAPE: (11606, 21)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.0144488\tvalid_0's l1: 0.0951078\n",
      "[100]\tvalid_0's l2: 0.0131209\tvalid_0's l1: 0.0903507\n",
      "[150]\tvalid_0's l2: 0.0129698\tvalid_0's l1: 0.0897719\n",
      "[200]\tvalid_0's l2: 0.0129474\tvalid_0's l1: 0.0896503\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's l2: 0.0129435\tvalid_0's l1: 0.0896177\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.093253 MSE: 0.013949\n",
      "TEST MAE: 0.093849 MSE: 0.014215\n",
      "teamA_cat3\n",
      "TRAIN SHAPE: (40680, 19) TEST SHAPE: (10170, 19)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 1.61083\tvalid_0's l1: 1.01631\n",
      "[100]\tvalid_0's l2: 1.60678\tvalid_0's l1: 1.01238\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's l2: 1.60656\tvalid_0's l1: 1.01237\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 1.010667 MSE: 1.597921\n",
      "TEST MAE: 1.012366 MSE: 1.606562\n",
      "TRAIN SHAPE: (40680, 20) TEST SHAPE: (10170, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.105481\tvalid_0's l1: 0.269097\n",
      "[100]\tvalid_0's l2: 0.10494\tvalid_0's l1: 0.267558\n",
      "[150]\tvalid_0's l2: 0.104834\tvalid_0's l1: 0.26729\n",
      "[200]\tvalid_0's l2: 0.104839\tvalid_0's l1: 0.267197\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's l2: 0.104802\tvalid_0's l1: 0.267167\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.30867 MSE: 0.129995\n",
      "TEST MAE: 0.314939 MSE: 0.135366\n",
      "!!!!!!! ('teamA_cat3_relativeRH_V3', 'teamA_cat3_relative_pred_prio_error', 'teamA_cat3_played_pred', True)\n",
      "teamA_cat5VScat0\n",
      "TRAIN SHAPE: (38726, 19) TEST SHAPE: (9682, 19)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 1.2186\tvalid_0's l1: 0.895504\n",
      "[100]\tvalid_0's l2: 1.21421\tvalid_0's l1: 0.892104\n",
      "[150]\tvalid_0's l2: 1.21345\tvalid_0's l1: 0.891579\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's l2: 1.21325\tvalid_0's l1: 0.89149\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.890205 MSE: 1.194919\n",
      "TEST MAE: 0.89149 MSE: 1.213249\n",
      "TRAIN SHAPE: (38726, 20) TEST SHAPE: (9682, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.0239\tvalid_0's l1: 0.0954828\n",
      "[100]\tvalid_0's l2: 0.0238982\tvalid_0's l1: 0.0953537\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's l2: 0.023886\tvalid_0's l1: 0.095389\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.100936 MSE: 0.032426\n",
      "TEST MAE: 0.101283 MSE: 0.032222\n",
      "!!!!!!! ('teamA_cat5VScat0_relativeRH_V3', 'teamA_cat5VScat0_relative_pred_prio_error', 'teamA_cat5VScat0_played_pred', True)\n",
      "teamA_cat5VScat2\n",
      "TRAIN SHAPE: (24816, 19) TEST SHAPE: (6205, 19)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.652577\tvalid_0's l1: 0.662985\n",
      "[100]\tvalid_0's l2: 0.65233\tvalid_0's l1: 0.66186\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's l2: 0.652224\tvalid_0's l1: 0.66182\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.645845 MSE: 0.609414\n",
      "TEST MAE: 0.66182 MSE: 0.652224\n",
      "TRAIN SHAPE: (24816, 20) TEST SHAPE: (6205, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.131457\tvalid_0's l1: 0.311189\n",
      "[100]\tvalid_0's l2: 0.131317\tvalid_0's l1: 0.310515\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's l2: 0.131301\tvalid_0's l1: 0.310538\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.350819 MSE: 0.159692\n",
      "TEST MAE: 0.351401 MSE: 0.160656\n",
      "!!!!!!! ('teamA_cat5VScat2_relativeRH_V3', 'teamA_cat5VScat2_relative_pred_prio_error', 'teamA_cat5VScat2_played_pred', True)\n",
      "teamA_cat4\n",
      "TRAIN SHAPE: (46420, 19) TEST SHAPE: (11606, 19)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 13.3566\tvalid_0's l1: 2.93457\n",
      "[100]\tvalid_0's l2: 13.1884\tvalid_0's l1: 2.91274\n",
      "[150]\tvalid_0's l2: 13.1661\tvalid_0's l1: 2.90929\n",
      "[200]\tvalid_0's l2: 13.1572\tvalid_0's l1: 2.9077\n",
      "Early stopping, best iteration is:\n",
      "[199]\tvalid_0's l2: 13.1564\tvalid_0's l1: 2.90768\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 2.8628 MSE: 12.822129\n",
      "TEST MAE: 2.907684 MSE: 13.156395\n",
      "TRAIN SHAPE: (46420, 20) TEST SHAPE: (11606, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.0222129\tvalid_0's l1: 0.115458\n",
      "[100]\tvalid_0's l2: 0.0217982\tvalid_0's l1: 0.114517\n",
      "[150]\tvalid_0's l2: 0.0217371\tvalid_0's l1: 0.114433\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's l2: 0.0217299\tvalid_0's l1: 0.114419\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.127609 MSE: 0.027189\n",
      "TEST MAE: 0.12889 MSE: 0.027677\n",
      "!!!!!!! ('teamA_cat4_relativeRH_V3', 'teamA_cat4_relative_pred_prio_error', 'teamA_cat4_played_pred', True)\n",
      "teamA_cat2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SHAPE: (27180, 19) TEST SHAPE: (6796, 19)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.737235\tvalid_0's l1: 0.703513\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's l2: 0.73676\tvalid_0's l1: 0.702523\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.700802 MSE: 0.741627\n",
      "TEST MAE: 0.702523 MSE: 0.73676\n",
      "TRAIN SHAPE: (27180, 20) TEST SHAPE: (6796, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.132889\tvalid_0's l1: 0.314318\n",
      "[100]\tvalid_0's l2: 0.132831\tvalid_0's l1: 0.313628\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's l2: 0.132781\tvalid_0's l1: 0.313832\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.357745 MSE: 0.163222\n",
      "TEST MAE: 0.359518 MSE: 0.164593\n",
      "!!!!!!! ('teamA_cat2_relativeRH_V3', 'teamA_cat2_relative_pred_prio_error', 'teamA_cat2_played_pred', True)\n",
      "teamA_cat0\n",
      "TRAIN SHAPE: (41277, 19) TEST SHAPE: (10320, 19)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 1.51994\tvalid_0's l1: 1.00955\n",
      "[100]\tvalid_0's l2: 1.50992\tvalid_0's l1: 1.00242\n",
      "[150]\tvalid_0's l2: 1.50755\tvalid_0's l1: 1.00081\n",
      "[200]\tvalid_0's l2: 1.50539\tvalid_0's l1: 0.999913\n",
      "[250]\tvalid_0's l2: 1.50439\tvalid_0's l1: 0.999156\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's l2: 1.50436\tvalid_0's l1: 0.998952\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.971195 MSE: 1.419392\n",
      "TEST MAE: 0.998952 MSE: 1.504358\n",
      "TRAIN SHAPE: (41277, 20) TEST SHAPE: (10320, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.0199941\tvalid_0's l1: 0.0911307\n",
      "[100]\tvalid_0's l2: 0.0199853\tvalid_0's l1: 0.090942\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's l2: 0.0199773\tvalid_0's l1: 0.0908544\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.09988 MSE: 0.029936\n",
      "TEST MAE: 0.097269 MSE: 0.027797\n",
      "!!!!!!! ('teamA_cat0_relativeRH_V3', 'teamA_cat0_relative_pred_prio_error', 'teamA_cat0_played_pred', True)\n",
      "teamA_cat1\n",
      "TRAIN SHAPE: (39216, 19) TEST SHAPE: (9805, 19)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 1.39061\tvalid_0's l1: 0.966062\n",
      "[100]\tvalid_0's l2: 1.38515\tvalid_0's l1: 0.961736\n",
      "[150]\tvalid_0's l2: 1.38316\tvalid_0's l1: 0.960343\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's l2: 1.38318\tvalid_0's l1: 0.959847\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.947441 MSE: 1.359135\n",
      "TEST MAE: 0.959847 MSE: 1.383176\n",
      "TRAIN SHAPE: (39216, 20) TEST SHAPE: (9805, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.0716932\tvalid_0's l1: 0.218205\n",
      "[100]\tvalid_0's l2: 0.0714571\tvalid_0's l1: 0.217588\n",
      "[150]\tvalid_0's l2: 0.071417\tvalid_0's l1: 0.217357\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's l2: 0.0714083\tvalid_0's l1: 0.217325\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.251387 MSE: 0.097297\n",
      "TEST MAE: 0.255526 MSE: 0.100563\n",
      "!!!!!!! ('teamA_cat1_relativeRH_V3', 'teamA_cat1_relative_pred_prio_error', 'teamA_cat1_played_pred', True)\n",
      "teamA_cat5VScat1\n",
      "TRAIN SHAPE: (34488, 19) TEST SHAPE: (8623, 19)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's l2: 1.03338\tvalid_0's l1: 0.783315\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.781474 MSE: 1.055231\n",
      "TEST MAE: 0.783315 MSE: 1.033376\n",
      "TRAIN SHAPE: (34488, 20) TEST SHAPE: (8623, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.079832\tvalid_0's l1: 0.228632\n",
      "[100]\tvalid_0's l2: 0.0796929\tvalid_0's l1: 0.227954\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's l2: 0.079683\tvalid_0's l1: 0.227965\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.256226 MSE: 0.104258\n",
      "TEST MAE: 0.259441 MSE: 0.107113\n",
      "!!!!!!! ('teamA_cat5VScat1_relativeRH_V3', 'teamA_cat5VScat1_relative_pred_prio_error', 'teamA_cat5VScat1_played_pred', True)\n",
      "teamA_cat5VScat3\n",
      "TRAIN SHAPE: (29107, 19) TEST SHAPE: (7277, 19)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.804951\tvalid_0's l1: 0.727964\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l2: 0.803769\tvalid_0's l1: 0.726781\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.727557 MSE: 0.812003\n",
      "TEST MAE: 0.726781 MSE: 0.803769\n",
      "TRAIN SHAPE: (29107, 20) TEST SHAPE: (7277, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.139063\tvalid_0's l1: 0.320136\n",
      "[100]\tvalid_0's l2: 0.138894\tvalid_0's l1: 0.319372\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's l2: 0.138829\tvalid_0's l1: 0.319432\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.373703 MSE: 0.172934\n",
      "TEST MAE: 0.372939 MSE: 0.173716\n",
      "!!!!!!! ('teamA_cat5VScat3_relativeRH_V3', 'teamA_cat5VScat3_relative_pred_prio_error', 'teamA_cat5VScat3_played_pred', True)\n",
      "teamA_cat5VScat4\n",
      "TRAIN SHAPE: (46420, 19) TEST SHAPE: (11606, 19)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 7.46352\tvalid_0's l1: 2.25393\n",
      "[100]\tvalid_0's l2: 7.40326\tvalid_0's l1: 2.24509\n",
      "[150]\tvalid_0's l2: 7.38367\tvalid_0's l1: 2.24152\n",
      "[200]\tvalid_0's l2: 7.36768\tvalid_0's l1: 2.23882\n",
      "[250]\tvalid_0's l2: 7.36399\tvalid_0's l1: 2.23837\n",
      "[300]\tvalid_0's l2: 7.36245\tvalid_0's l1: 2.23797\n",
      "Early stopping, best iteration is:\n",
      "[276]\tvalid_0's l2: 7.36121\tvalid_0's l1: 2.23793\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 2.169757 MSE: 6.996706\n",
      "TEST MAE: 2.237933 MSE: 7.361206\n",
      "TRAIN SHAPE: (46420, 20) TEST SHAPE: (11606, 20)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.0276471\tvalid_0's l1: 0.130807\n",
      "[100]\tvalid_0's l2: 0.0272562\tvalid_0's l1: 0.130096\n",
      "[150]\tvalid_0's l2: 0.0272098\tvalid_0's l1: 0.13008\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's l2: 0.0271988\tvalid_0's l1: 0.130062\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.140584 MSE: 0.031606\n",
      "TEST MAE: 0.141111 MSE: 0.031747\n",
      "!!!!!!! ('teamA_cat5VScat4_relativeRH_V3', 'teamA_cat5VScat4_relative_pred_prio_error', 'teamA_cat5VScat4_played_pred', True)\n",
      "('teamA_cat3_relativeRH_V3', 'teamA_cat3_relative_pred_prio_error', 'teamA_cat3_played_pred', True)\n",
      "368.13499999\n",
      "('teamA_cat5VScat0_relativeRH_V3', 'teamA_cat5VScat0_relative_pred_prio_error', 'teamA_cat5VScat0_played_pred', True)\n",
      "381.913000107\n",
      "('teamA_cat5VScat2_relativeRH_V3', 'teamA_cat5VScat2_relative_pred_prio_error', 'teamA_cat5VScat2_played_pred', True)\n",
      "336.101999998\n",
      "('teamA_cat4_relativeRH_V3', 'teamA_cat4_relative_pred_prio_error', 'teamA_cat4_played_pred', True)\n",
      "359.565000057\n",
      "('teamA_cat2_relativeRH_V3', 'teamA_cat2_relative_pred_prio_error', 'teamA_cat2_played_pred', True)\n",
      "372.68200016\n",
      "('teamA_cat0_relativeRH_V3', 'teamA_cat0_relative_pred_prio_error', 'teamA_cat0_played_pred', True)\n",
      "301.88499999\n",
      "('teamA_cat1_relativeRH_V3', 'teamA_cat1_relative_pred_prio_error', 'teamA_cat1_played_pred', True)\n",
      "330.141000032\n",
      "('teamA_cat5VScat1_relativeRH_V3', 'teamA_cat5VScat1_relative_pred_prio_error', 'teamA_cat5VScat1_played_pred', True)\n",
      "352.40899992\n",
      "('teamA_cat5VScat3_relativeRH_V3', 'teamA_cat5VScat3_relative_pred_prio_error', 'teamA_cat5VScat3_played_pred', True)\n",
      "340.443000078\n",
      "('teamA_cat5VScat4_relativeRH_V3', 'teamA_cat5VScat4_relative_pred_prio_error', 'teamA_cat5VScat4_played_pred', True)\n",
      "353.700000048\n",
      "teamA_cat3_played\n",
      "teamA_cat5VScat0_played\n",
      "teamA_cat5VScat2_played\n",
      "teamA_cat4_played\n",
      "teamA_cat2_played\n",
      "teamA_cat0_played\n",
      "teamA_cat1_played\n",
      "teamA_cat5VScat1_played\n",
      "teamA_cat5VScat3_played\n",
      "teamA_cat5VScat4_played\n",
      "(13445, 415)\n",
      "['teamAavgIncome', 'teamAfirPlaceRatio', 'teamAmaxPrPoolRatio', 'ratingA_HLTV', 'teamAId', 'teamAkef', 'teamAperMarja', 'teamAper'] ['teamBavgIncome', 'teamBfirPlaceRatio', 'teamBmaxPrPoolRatio', 'ratingB_HLTV', 'teamBId', 'teamBkef', 'teamBperMarja', 'teamBper']\n",
      "TRAIN SHAPE: (12265, 21) TEST SHAPE: (3067, 21)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 0.0198751\tvalid_0's l1: 0.117274\n",
      "[100]\tvalid_0's l2: 0.0171599\tvalid_0's l1: 0.105657\n",
      "[150]\tvalid_0's l2: 0.0165755\tvalid_0's l1: 0.102572\n",
      "[200]\tvalid_0's l2: 0.0163269\tvalid_0's l1: 0.101198\n",
      "[250]\tvalid_0's l2: 0.0161686\tvalid_0's l1: 0.100479\n",
      "[300]\tvalid_0's l2: 0.0161031\tvalid_0's l1: 0.10014\n",
      "[350]\tvalid_0's l2: 0.0160131\tvalid_0's l1: 0.0997469\n",
      "[400]\tvalid_0's l2: 0.0159759\tvalid_0's l1: 0.0995058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[404]\tvalid_0's l2: 0.0159717\tvalid_0's l1: 0.0994966\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.087369 MSE: 0.012338\n",
      "TEST MAE: 0.099497 MSE: 0.015972\n",
      "['matchFormat', 'matchType', 'mapPicker', 'teamAavgIncome', 'teamBavgIncome', 'firPlace', 'maxPrizeUSD', 'teamAfirPlaceRatio', 'teamBfirPlaceRatio', 'teamAmaxPrPoolRatio', 'teamBmaxPrPoolRatio', 'teamAabsForceProb', 'teamAabsForceWProb', 'teamAabsForceWeightedProb', 'teamAabsForceWeightedWProb', 'teamAabsForceSpecProb', 'teamAabsForceSpecWProb', 'teamAabsForceWeightedSpecProb', 'teamAabsForceWeightedSpecWProb', 'ratingA_HLTV', 'ratingB_HLTV', 'bookPer', 'teamA_cat3_relative_pred_fixed', 'teamA_cat5VScat0_relative_pred_fixed', 'teamA_cat5VScat2_relative_pred_fixed', 'teamA_cat4_relative_pred_fixed', 'teamA_cat2_relative_pred_fixed', 'teamA_cat0_relative_pred_fixed', 'teamA_cat1_relative_pred_fixed', 'teamA_cat5VScat1_relative_pred_fixed', 'teamA_cat5VScat3_relative_pred_fixed', 'teamA_cat5VScat4_relative_pred_fixed', 'teamAPistolHistoryWin', 'teamAPistolHistoryLoose', 'teamAPistolHistoryWinLooseDif', 'teamAPistolHistoryWinCount', 'teamAPistolHistoryLooseCount', 'teamAPistolHistoryWinCountLooseCountDif']\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 45.4667\tvalid_0's l1: 5.59221\n",
      "[100]\tvalid_0's l2: 44.2798\tvalid_0's l1: 5.44793\n",
      "[150]\tvalid_0's l2: 44.0777\tvalid_0's l1: 5.42093\n",
      "[200]\tvalid_0's l2: 44.026\tvalid_0's l1: 5.41227\n",
      "[250]\tvalid_0's l2: 43.9891\tvalid_0's l1: 5.40701\n",
      "[300]\tvalid_0's l2: 43.9628\tvalid_0's l1: 5.40256\n",
      "Early stopping, best iteration is:\n",
      "[323]\tvalid_0's l2: 43.9552\tvalid_0's l1: 5.40133\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 5.212731 MSE: 40.854244\n",
      "TEST MAE: 5.401327 MSE: 43.955215\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 45.0459\tvalid_0's l1: 5.53667\n",
      "[100]\tvalid_0's l2: 43.8\tvalid_0's l1: 5.40039\n",
      "[150]\tvalid_0's l2: 43.5614\tvalid_0's l1: 5.37275\n",
      "[200]\tvalid_0's l2: 43.4691\tvalid_0's l1: 5.36302\n",
      "[250]\tvalid_0's l2: 43.4083\tvalid_0's l1: 5.35633\n",
      "[300]\tvalid_0's l2: 43.3549\tvalid_0's l1: 5.35148\n",
      "[350]\tvalid_0's l2: 43.3206\tvalid_0's l1: 5.34738\n",
      "Early stopping, best iteration is:\n",
      "[370]\tvalid_0's l2: 43.3076\tvalid_0's l1: 5.34611\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 5.20354 MSE: 40.666427\n",
      "TEST MAE: 5.346112 MSE: 43.307633\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 43.7879\tvalid_0's l1: 5.49105\n",
      "[100]\tvalid_0's l2: 42.1211\tvalid_0's l1: 5.30833\n",
      "[150]\tvalid_0's l2: 41.7796\tvalid_0's l1: 5.26954\n",
      "[200]\tvalid_0's l2: 41.6695\tvalid_0's l1: 5.25917\n",
      "[250]\tvalid_0's l2: 41.6046\tvalid_0's l1: 5.25253\n",
      "[300]\tvalid_0's l2: 41.5674\tvalid_0's l1: 5.24915\n",
      "[350]\tvalid_0's l2: 41.505\tvalid_0's l1: 5.2446\n",
      "[400]\tvalid_0's l2: 41.4694\tvalid_0's l1: 5.24135\n",
      "[450]\tvalid_0's l2: 41.4551\tvalid_0's l1: 5.24028\n",
      "[500]\tvalid_0's l2: 41.436\tvalid_0's l1: 5.23763\n",
      "[550]\tvalid_0's l2: 41.4172\tvalid_0's l1: 5.23586\n",
      "[600]\tvalid_0's l2: 41.3844\tvalid_0's l1: 5.23329\n",
      "Early stopping, best iteration is:\n",
      "[615]\tvalid_0's l2: 41.3792\tvalid_0's l1: 5.2328\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 5.118523 MSE: 39.35995\n",
      "TEST MAE: 5.232801 MSE: 41.379218\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 46.3976\tvalid_0's l1: 5.65754\n",
      "[100]\tvalid_0's l2: 45.3142\tvalid_0's l1: 5.52848\n",
      "[150]\tvalid_0's l2: 45.1051\tvalid_0's l1: 5.50284\n",
      "[200]\tvalid_0's l2: 45.0119\tvalid_0's l1: 5.49454\n",
      "[250]\tvalid_0's l2: 44.9581\tvalid_0's l1: 5.48989\n",
      "[300]\tvalid_0's l2: 44.9206\tvalid_0's l1: 5.48736\n",
      "[350]\tvalid_0's l2: 44.8658\tvalid_0's l1: 5.48423\n",
      "[400]\tvalid_0's l2: 44.8564\tvalid_0's l1: 5.48407\n",
      "[450]\tvalid_0's l2: 44.8373\tvalid_0's l1: 5.48206\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's l2: 44.823\tvalid_0's l1: 5.48122\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 5.134432 MSE: 39.7694\n",
      "TEST MAE: 5.481222 MSE: 44.822998\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 44.6667\tvalid_0's l1: 5.54534\n",
      "[100]\tvalid_0's l2: 43.5934\tvalid_0's l1: 5.4164\n",
      "[150]\tvalid_0's l2: 43.373\tvalid_0's l1: 5.38729\n",
      "[200]\tvalid_0's l2: 43.3188\tvalid_0's l1: 5.38031\n",
      "[250]\tvalid_0's l2: 43.2762\tvalid_0's l1: 5.37732\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's l2: 43.2762\tvalid_0's l1: 5.37732\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 5.255336 MSE: 41.533189\n",
      "TEST MAE: 5.377324 MSE: 43.276205\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 45.351\tvalid_0's l1: 5.58797\n",
      "[100]\tvalid_0's l2: 43.9251\tvalid_0's l1: 5.43846\n",
      "[150]\tvalid_0's l2: 43.6006\tvalid_0's l1: 5.40163\n",
      "[200]\tvalid_0's l2: 43.4777\tvalid_0's l1: 5.38852\n",
      "[250]\tvalid_0's l2: 43.4076\tvalid_0's l1: 5.38178\n",
      "[300]\tvalid_0's l2: 43.369\tvalid_0's l1: 5.37779\n",
      "[350]\tvalid_0's l2: 43.3366\tvalid_0's l1: 5.37611\n",
      "Early stopping, best iteration is:\n",
      "[326]\tvalid_0's l2: 43.3408\tvalid_0's l1: 5.37588\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 5.21588 MSE: 40.930828\n",
      "TEST MAE: 5.375875 MSE: 43.340752\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[50]\tvalid_0's l2: 45.6906\tvalid_0's l1: 5.62308\n",
      "[100]\tvalid_0's l2: 44.1989\tvalid_0's l1: 5.45854\n",
      "[150]\tvalid_0's l2: 43.8623\tvalid_0's l1: 5.41921\n",
      "[200]\tvalid_0's l2: 43.7272\tvalid_0's l1: 5.40564\n",
      "[250]\tvalid_0's l2: 43.6346\tvalid_0's l1: 5.3963\n",
      "[300]\tvalid_0's l2: 43.5755\tvalid_0's l1: 5.39033\n",
      "[350]\tvalid_0's l2: 43.5204\tvalid_0's l1: 5.3855\n",
      "[400]\tvalid_0's l2: 43.4975\tvalid_0's l1: 5.38312\n",
      "Early stopping, best iteration is:\n",
      "[394]\tvalid_0's l2: 43.4916\tvalid_0's l1: 5.38294\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 5.210943 MSE: 40.844137\n",
      "TEST MAE: 5.382942 MSE: 43.491639\n",
      "TEST ACCURACY 0.6907254458414436\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-c0ef69eee1b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'HLTV'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./rating_systems/elo0/1_1000_28.csv', sep=';')\n",
    "newIndex = np.arange(df.shape[0])\n",
    "newIndex[::2] = df.index.values[:df.shape[0]//2]\n",
    "newIndex[1::2] = df.index.values[df.shape[0]//2:]\n",
    "df.loc[df.index] = df.loc[newIndex].values\n",
    "df = df.iloc[int(df.shape[0]*0.1):]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# newIndex = np.arange(newdf.shape[0])\n",
    "# newIndex[::2] = newdf.index.values[:newdf.shape[0]//2]\n",
    "# newIndex[1::2] = newdf.index.values[newdf.shape[0]//2:]\n",
    "# newdf.loc[newdf.index] = newdf.loc[newIndex].values\n",
    "# newdf = newdf.iloc[int(newdf.shape[0]*0.1):]\n",
    "# newdf.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "stack1lvl = pd.DataFrame(index=df.index)\n",
    "print stack1lvl.shape\n",
    "prefixes = [\n",
    "            'HLTV',\n",
    "            'elo0',\n",
    "            'elo0Inf',\n",
    "            'elo5',\n",
    "            'elo5Inf',\n",
    "            'glicko',\n",
    "            'glicko2',\n",
    "            'trueskill',\n",
    "            'trueskillUnrate'\n",
    "]\n",
    "\n",
    "for prefix in prefixes:\n",
    "#     if prefix=='HLTV':\n",
    "#         continue\n",
    "        \n",
    "    print '!!!!!!!!!!! PREFIX:', prefix\n",
    "    \n",
    "    df = pd.read_csv('./rating_systems/%s/1_1000_28.csv'%(prefix), sep=';')\n",
    "    commonData = pd.read_csv('./data/COMMONDATA.csv')\n",
    "    print df.shape, commonData.shape\n",
    "\n",
    "    difColumns = list(set(commonData.columns.values) - set(df.columns.values))\n",
    "    # difColumns = list(set(df.columns.values).intersection(set(commonData.columns.values)))\n",
    "    print len(difColumns)\n",
    "\n",
    "    df = pd.merge(df, commonData[difColumns], left_index=True, right_index=True, copy=False)\n",
    "\n",
    "    df['map_str'] = df['map'].values\n",
    "\n",
    "    # map Label encoding\n",
    "    le = LabelEncoder()\n",
    "    df['map'] = le.fit(df['map'].values).transform(df['map'].values)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # define results for every half (half_0 and half_1)\n",
    "    df['half_0_difScore'] = 0\n",
    "    df['half_1_difScore'] = 0\n",
    "    df.loc[df['teamAHalf_0']==1, 'half_0_difScore'] = df.loc[df['teamAHalf_0']==1, 'teamACTScore'] - df.loc[df['teamAHalf_0']==1, 'teamBTScore']\n",
    "    df.loc[df['teamAHalf_0']==1, 'half_1_difScore'] = df.loc[df['teamAHalf_0']==1, 'teamATScore'] - df.loc[df['teamAHalf_0']==1, 'teamBCTScore']\n",
    "    df.loc[df['teamAHalf_0']==0, 'half_0_difScore'] = df.loc[df['teamAHalf_0']==0, 'teamATScore'] - df.loc[df['teamAHalf_0']==0, 'teamBCTScore']\n",
    "    df.loc[df['teamAHalf_0']==0, 'half_1_difScore'] = df.loc[df['teamAHalf_0']==0, 'teamACTScore'] - df.loc[df['teamAHalf_0']==0, 'teamBTScore']\n",
    "\n",
    "    gc.collect()\n",
    "    print 'SHAPE', df.shape\n",
    "    \n",
    "    pred_clmns = [\n",
    "              'matchFormat', 'matchType', 'mapPicker', 'map',\n",
    "              'teamAHalf_0',\n",
    "              'teamAavgIncome', 'teamBavgIncome', \n",
    "              'teamAfirPlaceRatio', 'teamBfirPlaceRatio', \n",
    "#               'teamARNOHForce', 'teamBRNOHForce', \n",
    "#               'teamARNOHForceSpec', 'teamBRNOHForceSpec', \n",
    "              'teamAabsForceProb', 'teamAabsForceWProb', \n",
    "              'teamAabsForceWeightedProb', 'teamAabsForceWeightedWProb', \n",
    "              'teamAabsForceSpecProb', 'teamAabsForceSpecWProb', \n",
    "              'teamAabsForceWeightedSpecProb', 'teamAabsForceWeightedSpecWProb', \n",
    "              'ratingA_%s'%prefix, 'ratingB_%s'%prefix,\n",
    "             ]\n",
    "    #    1- \n",
    "    df = firstHalfPistolPrediction(df, pred_clmns)\n",
    "    \n",
    "    pred_clmns = [\n",
    "                  'matchFormat', 'matchType', 'mapPicker', 'map',\n",
    "                  'teamAHalf_0', 'teamAPistol_half_0', 'half_0_difScore', 'teamAPistol_half_0_pred', \n",
    "                  'teamAavgIncome', 'teamBavgIncome', \n",
    "                  'teamAfirPlaceRatio', 'teamBfirPlaceRatio', \n",
    "    #               'teamARNOHForce', 'teamBRNOHForce', \n",
    "    #               'teamARNOHForceSpec', 'teamBRNOHForceSpec', \n",
    "                  'teamAabsForceProb', 'teamAabsForceWProb', \n",
    "                  'teamAabsForceWeightedProb', 'teamAabsForceWeightedWProb', \n",
    "                  'teamAabsForceSpecProb', 'teamAabsForceSpecWProb', \n",
    "                  'teamAabsForceWeightedSpecProb', 'teamAabsForceWeightedSpecWProb', \n",
    "                  'ratingA_%s'%prefix, 'ratingB_%s'%prefix,\n",
    "                 ]\n",
    "    #    2-    1-     1- \n",
    "    df = secondHalfPistolPrediction(df, pred_clmns)\n",
    "    \n",
    "    pred_clmns_0 = [\n",
    "                    'matchlinkId', 'teamAId', 'teamBId', 'date',\n",
    "                  'matchFormat', 'matchType', 'mapPicker', 'map', 'map_str',\n",
    "                  'teamAHalf_0',\n",
    "                  'teamAavgIncome', 'teamBavgIncome', \n",
    "                  'teamAfirPlaceRatio', 'teamBfirPlaceRatio', \n",
    "    #               'teamARNOHForce', 'teamBRNOHForce', \n",
    "    #               'teamARNOHForceSpec', 'teamBRNOHForceSpec', \n",
    "                  'teamAabsForceProb', 'teamAabsForceWProb', \n",
    "                  'teamAabsForceWeightedProb', 'teamAabsForceWeightedWProb', \n",
    "                  'teamAabsForceSpecProb', 'teamAabsForceSpecWProb', \n",
    "                  'teamAabsForceWeightedSpecProb', 'teamAabsForceWeightedSpecWProb', \n",
    "                  'ratingA_%s'%prefix, 'ratingB_%s'%prefix, 'teamAPistol_half_0_pred', 'teamAPistol_half_0'\n",
    "    #               'ratingDif'\n",
    "                 ]\n",
    "    pred_clmns_1 = [\n",
    "                'matchlinkId', 'teamAId', 'teamBId', 'date',\n",
    "                  'matchFormat', 'matchType', 'mapPicker', 'map', 'map_str',\n",
    "                  'teamAHalf_1',\n",
    "                  'teamAavgIncome', 'teamBavgIncome', \n",
    "                  'teamAfirPlaceRatio', 'teamBfirPlaceRatio', \n",
    "    #               'teamARNOHForce', 'teamBRNOHForce', \n",
    "    #               'teamARNOHForceSpec', 'teamBRNOHForceSpec', \n",
    "                  'teamAabsForceProb', 'teamAabsForceWProb', \n",
    "                  'teamAabsForceWeightedProb', 'teamAabsForceWeightedWProb', \n",
    "                  'teamAabsForceSpecProb', 'teamAabsForceSpecWProb', \n",
    "                  'teamAabsForceWeightedSpecProb', 'teamAabsForceWeightedSpecWProb', \n",
    "                  'ratingA_%s'%prefix, 'ratingB_%s'%prefix, 'teamAPistol_half_1_pred', 'teamAPistol_half_1'\n",
    "    #               'ratingDif'\n",
    "                 ]\n",
    "    \n",
    "    common_pistol = pd.DataFrame(np.concatenate((df[df['teamAPistol_half_0']!=0][pred_clmns_0].values, df[df['teamAPistol_half_1']!=0][pred_clmns_1].values)))\n",
    "    common_pistol.columns = [\n",
    "                    'matchlinkId', 'teamAId', 'teamBId', 'date',\n",
    "                  'matchFormat', 'matchType', 'mapPicker', 'map', 'map_str',\n",
    "                  'teamAHalf',\n",
    "                  'teamAavgIncome', 'teamBavgIncome', \n",
    "                  'teamAfirPlaceRatio', 'teamBfirPlaceRatio', \n",
    "    #               'teamARNOHForce', 'teamBRNOHForce', \n",
    "    #               'teamARNOHForceSpec', 'teamBRNOHForceSpec', \n",
    "                  'teamAabsForceProb', 'teamAabsForceWProb', \n",
    "                  'teamAabsForceWeightedProb', 'teamAabsForceWeightedWProb', \n",
    "                  'teamAabsForceSpecProb', 'teamAabsForceSpecWProb', \n",
    "                  'teamAabsForceWeightedSpecProb', 'teamAabsForceWeightedSpecWProb', \n",
    "                  'ratingA_%s'%prefix, 'ratingB_%s'%prefix, 'teamAPistol_pred', 'teamAPistol', \n",
    "    #               'ratingDif'\n",
    "                 ]\n",
    "    gc.collect()\n",
    "    common_pistol['teamAPistol'].replace({-1: 0}, inplace=True)\n",
    "    common_pistol[['matchlinkId', 'teamAId', 'teamBId', 'matchFormat', 'matchType', 'mapPicker', 'map', 'teamAHalf', 'teamAPistol']] = common_pistol[['matchlinkId', 'teamAId', 'teamBId', 'matchFormat', 'matchType', 'mapPicker', 'map', 'teamAHalf', 'teamAPistol']].astype(int)\n",
    "    common_pistol[['teamAavgIncome', 'teamBavgIncome', 'teamAfirPlaceRatio', 'teamBfirPlaceRatio', 'teamAabsForceProb', 'teamAabsForceWProb', 'teamAabsForceWeightedProb', 'teamAabsForceWeightedWProb', 'teamAabsForceSpecProb', 'teamAabsForceSpecWProb', 'teamAabsForceWeightedSpecProb', 'teamAabsForceWeightedSpecWProb', 'ratingA_%s'%prefix, 'ratingB_%s'%prefix, 'teamAPistol_pred', ]] = common_pistol[['teamAavgIncome', 'teamBavgIncome', 'teamAfirPlaceRatio', 'teamBfirPlaceRatio', 'teamAabsForceProb', 'teamAabsForceWProb', 'teamAabsForceWeightedProb', 'teamAabsForceWeightedWProb', 'teamAabsForceSpecProb', 'teamAabsForceSpecWProb', 'teamAabsForceWeightedSpecProb', 'teamAabsForceWeightedSpecWProb', 'ratingA_%s'%prefix, 'ratingB_%s'%prefix, 'teamAPistol_pred', ]].astype(float)\n",
    "    common_pistol['date'] = pd.to_datetime(common_pistol['date'])\n",
    "    common_pistol = common_pistol.sort_values(by='date', ascending=True)\n",
    "    common_pistol.reset_index(drop=True, inplace=True)\n",
    "    print common_pistol.shape\n",
    "    print common_pistol['teamAPistol'].value_counts()\n",
    "\n",
    "    #  ['Win', 'Loose', 'WinCount', 'LooseCount'] =>\n",
    "    # [  ,   ,  ,  ]\n",
    "    iterateHistoryClmns = [\n",
    "                        ('teamAPistolHistory', 'teamAPistol_pred', 'teamAPistol', True),\n",
    "                        ]\n",
    "\n",
    "    days = 28\n",
    "    df = pistolHistoryCalculation(df, common_pistol, days, iterateHistoryClmns)\n",
    "    common_pistol = pd.merge(common_pistol, df[['matchlinkId', 'teamAId', 'teamBId', 'map', u'teamAPistolHistoryWin', u'teamAPistolHistoryLoose', 'teamAPistolHistoryWinLooseDif', u'teamAPistolHistoryWinCount', u'teamAPistolHistoryLooseCount', 'teamAPistolHistoryWinCountLooseCountDif',]], on=['matchlinkId', 'teamAId', 'teamBId', 'map'])\n",
    "    \n",
    "    pred_clmns = [\n",
    "                u'matchFormat', u'matchType', u'mapPicker', u'map', u'teamAHalf',\n",
    "               u'teamAavgIncome', u'teamBavgIncome', u'teamAfirPlaceRatio',\n",
    "               u'teamBfirPlaceRatio', u'teamAabsForceProb', u'teamAabsForceWProb',\n",
    "               u'teamAabsForceWeightedProb', u'teamAabsForceWeightedWProb',\n",
    "               u'teamAabsForceSpecProb', u'teamAabsForceSpecWProb',\n",
    "               u'teamAabsForceWeightedSpecProb', u'teamAabsForceWeightedSpecWProb',\n",
    "               u'ratingA_%s'%prefix, u'ratingB_%s'%prefix,\n",
    "    #           u'teamAPistol_pred', \n",
    "              u'teamAPistolHistoryWin', u'teamAPistolHistoryLoose', 'teamAPistolHistoryWinLooseDif',\n",
    "              u'teamAPistolHistoryWinCount', u'teamAPistolHistoryLooseCount', 'teamAPistolHistoryWinCountLooseCountDif',\n",
    "                 ]\n",
    "    #            \n",
    "    df = pistolPrediction(df, common_pistol, pred_clmns)\n",
    "    \n",
    "    #        CAT5VS[0,1,2,3,4]\n",
    "    for i in df.columns:\n",
    "        if 'played' in i and 'A' in i and 'pred' not in i:\n",
    "            print i\n",
    "            i = '_'.join(i.split('_')[:-1])\n",
    "            df[i+'_relative'] = -0.5\n",
    "            df.loc[df[i+'_played']>0, i+'_relative'] = df.loc[df[i+'_played']>0, i+'_win'] / df.loc[df[i+'_played']>0, i+'_played']\n",
    "            \n",
    "    for i in df.columns:\n",
    "        if 'alf' not in i and 'played' in i and 'A' in i and 'pred' not in i:\n",
    "            i = '_'.join(i.split('_')[:-1])\n",
    "            print i\n",
    "            \n",
    "            #          DIFSCORE\n",
    "            # Predicting 'cat_played' fot matches where 'cat_played' is absent. Predicting based on difScore\n",
    "            pred_clmns = [\n",
    "                          'matchFormat', 'matchType', 'mapPicker', 'map',\n",
    "                          'teamAHalf_0', \n",
    "                          'teamAavgIncome', 'teamBavgIncome', \n",
    "                          'teamAfirPlaceRatio', 'teamBfirPlaceRatio', \n",
    "            #               'teamARNOHForce', 'teamBRNOHForce', \n",
    "            #               'teamARNOHForceSpec', 'teamBRNOHForceSpec', \n",
    "                          'teamAabsForceProb', 'teamAabsForceWProb', \n",
    "                          'teamAabsForceWeightedProb', 'teamAabsForceWeightedWProb', \n",
    "                          'teamAabsForceSpecProb', 'teamAabsForceSpecWProb', \n",
    "                          'teamAabsForceWeightedSpecProb', 'teamAabsForceWeightedSpecWProb', \n",
    "                          'ratingA_%s'%prefix, 'ratingB_%s'%prefix, 'difScore', \n",
    "            #               'ratingDif'\n",
    "                         ]\n",
    "            \n",
    "            df = catPlayedApostorioPrediction(df, pred_clmns, i)\n",
    "\n",
    "            #            DIFSCORE\n",
    "            # Predicting 'cat_relative' fot matches where 'cat_relative'>=0. Predicting based on difScore and teamA_cat4_played_pred\n",
    "            pred_clmns = [\n",
    "                          'matchFormat', 'matchType', 'mapPicker', 'map',\n",
    "                          'teamAHalf_0', \n",
    "                          'teamAavgIncome', 'teamBavgIncome', \n",
    "                          'teamAfirPlaceRatio', 'teamBfirPlaceRatio', \n",
    "            #               'teamARNOHForce', 'teamBRNOHForce', \n",
    "            #               'teamARNOHForceSpec', 'teamBRNOHForceSpec', \n",
    "                          'teamAabsForceProb', 'teamAabsForceWProb', \n",
    "                          'teamAabsForceWeightedProb', 'teamAabsForceWeightedWProb', \n",
    "                          'teamAabsForceSpecProb', 'teamAabsForceSpecWProb', \n",
    "                          'teamAabsForceWeightedSpecProb', 'teamAabsForceWeightedSpecWProb', \n",
    "                          'ratingA_%s'%prefix, 'ratingB_%s'%prefix, 'difScore', i + '_played' + '_pred', \n",
    "            #               'ratingDif'\n",
    "                         ]\n",
    "\n",
    "            df = catRelativeApostorioPrediction(df, pred_clmns, i)\n",
    "\n",
    "    iterateColumns = []\n",
    "\n",
    "    #               \n",
    "    for i in df.columns:\n",
    "        if 'alf' not in i and 'played' in i and 'A' in i and 'pred' not in i:\n",
    "            i = '_'.join(i.split('_')[:-1])\n",
    "            print i\n",
    "            \n",
    "            #        \n",
    "            # Predicting 'cat_played' fot matches where 'cat_played' is absent. Predicting based on difScore\n",
    "            pred_clmns = [\n",
    "                          'matchFormat', 'matchType', 'mapPicker', 'map',\n",
    "                          'teamAHalf_0', \n",
    "                          'teamAavgIncome', 'teamBavgIncome', \n",
    "                          'teamAfirPlaceRatio', 'teamBfirPlaceRatio', \n",
    "            #               'teamARNOHForce', 'teamBRNOHForce', \n",
    "            #               'teamARNOHForceSpec', 'teamBRNOHForceSpec', \n",
    "                          'teamAabsForceProb', 'teamAabsForceWProb', \n",
    "                          'teamAabsForceWeightedProb', 'teamAabsForceWeightedWProb', \n",
    "                          'teamAabsForceSpecProb', 'teamAabsForceSpecWProb', \n",
    "                          'teamAabsForceWeightedSpecProb', 'teamAabsForceWeightedSpecWProb', \n",
    "                          'ratingA_%s'%prefix, 'ratingB_%s'%prefix,\n",
    "            #               'ratingDif'\n",
    "                         ]\n",
    "            \n",
    "            df = catPlayedPriorioPrediction(df, pred_clmns, i)\n",
    "            \n",
    "            #          \n",
    "            # Predicting 'cat_relative' fot matches where 'cat_relative'>=0. Predicting based on difScore and teamA_cat4_played_pred\n",
    "            pred_clmns = [\n",
    "                          'matchFormat', 'matchType', 'mapPicker', 'map',\n",
    "                          'teamAHalf_0', \n",
    "                          'teamAavgIncome', 'teamBavgIncome', \n",
    "                          'teamAfirPlaceRatio', 'teamBfirPlaceRatio', \n",
    "            #               'teamARNOHForce', 'teamBRNOHForce', \n",
    "            #               'teamARNOHForceSpec', 'teamBRNOHForceSpec', \n",
    "                          'teamAabsForceProb', 'teamAabsForceWProb', \n",
    "                          'teamAabsForceWeightedProb', 'teamAabsForceWeightedWProb', \n",
    "                          'teamAabsForceSpecProb', 'teamAabsForceSpecWProb', \n",
    "                          'teamAabsForceWeightedSpecProb', 'teamAabsForceWeightedSpecWProb', \n",
    "                          'ratingA_%s'%prefix, 'ratingB_%s'%prefix, i + '_played' + '_pred_prio', \n",
    "            #               'ratingDif'\n",
    "                         ]\n",
    "\n",
    "            df = catRelativePriorioPrediction(df, pred_clmns, i)\n",
    "\n",
    "            #          \n",
    "            # calculate prio error\n",
    "            df[i + '_relative' + '_pred_prio_error'] = df[i + '_relative' + '_pred'] - df[i + '_relative' + '_pred_prio']\n",
    "\n",
    "            iterateColumns.append((i+'_relativeRH_V3', i+'_relative_pred_prio_error', i+'_played_pred', True))\n",
    "            print '!!!!!!!', iterateColumns[-1]\n",
    "            \n",
    "            \n",
    "    #               \n",
    "    days = 28\n",
    "    df = catHistoryCalculation(df, days, iterateColumns)\n",
    "\n",
    "    #               \n",
    "    for i in df.columns:\n",
    "        if 'alf' not in i and 'played' in i and 'A' in i and 'pred' not in i and 'relative' not in i:\n",
    "            print i\n",
    "            i = '_'.join(i.split('_')[:-1])\n",
    "            df[i+'_relative_pred_fixed'] = df[i+'_relative_pred_prio'].values + df[i+'_relativeRH_V3'].values\n",
    "\n",
    "    # Predicting difScore\n",
    "    # regression\n",
    "    \n",
    "    newdf = df.copy()\n",
    "    newIndex = np.arange(newdf.shape[0])\n",
    "    newIndex[::2] = newdf.index.values[:newdf.shape[0]//2]\n",
    "    newIndex[1::2] = newdf.index.values[newdf.shape[0]//2:]\n",
    "    newdf.loc[newdf.index] = newdf.loc[newIndex].values\n",
    "    newdf = newdf.iloc[int(newdf.shape[0]*0.1):]\n",
    "    newdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#     newdf = newdf.iloc[int(newdf.shape[0]*0.1):]\n",
    "#     newdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    pred_clmns = [\n",
    "                 'matchFormat', 'matchType', 'mapPicker', 'teamAavgIncome', 'teamBavgIncome', \n",
    "                 'firPlace', 'maxPrizeUSD', 'teamAfirPlaceRatio', \n",
    "                 'teamBfirPlaceRatio', 'teamAmaxPrPoolRatio', 'teamBmaxPrPoolRatio', \n",
    "    #              'teamARNOHForce', 'teamBRNOHForce', 'teamARNOHForceSpec', 'teamBRNOHForceSpec', \n",
    "                 'teamAabsForceProb', 'teamAabsForceWProb', \n",
    "                 'teamAabsForceWeightedProb', 'teamAabsForceWeightedWProb', \n",
    "                 'teamAabsForceSpecProb', 'teamAabsForceSpecWProb', \n",
    "                 'teamAabsForceWeightedSpecProb', 'teamAabsForceWeightedSpecWProb', \n",
    "                 'ratingA_%s'%prefix, 'ratingB_%s'%prefix,\n",
    "    ]\n",
    "    \n",
    "    cols = pred_clmns\n",
    "    kefPred = kefPrediction(newdf.copy(), cols)\n",
    "    newdf['bookPer'] = kefPred.predict(newdf[cols])\n",
    "    \n",
    "    mainClmns = pred_clmns\n",
    "    mainClmns += ['bookPer']\n",
    "    mainClmns += [i for i in newdf.columns if 'fixed' in i] + ['teamAPistolHistoryWin', 'teamAPistolHistoryLoose', 'teamAPistolHistoryWinLooseDif', 'teamAPistolHistoryWinCount', 'teamAPistolHistoryLooseCount', 'teamAPistolHistoryWinCountLooseCountDif']\n",
    "    # mainClmns += ['teamAPistolHistoryWin', 'teamAPistolHistoryLoose']\n",
    "    print mainClmns\n",
    "\n",
    "    y_col = 'difScore'\n",
    "    cond = newdf[y_col]>=-16\n",
    "\n",
    "    tr_index = newdf[cond].iloc[:int(0.8*newdf[cond].shape[0])].index.values\n",
    "    te_index = newdf[cond].iloc[int(0.8*newdf[cond].shape[0]):].index.values\n",
    "\n",
    "    trIndParts = np.array_split(tr_index, 6)\n",
    "    for ind, trteInd in enumerate(trIndParts):\n",
    "        trtrInd = np.concatenate([trIndParts[j] for j in range(len(trIndParts)) if j!=ind])\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': {'l2', 'l1'},\n",
    "            'num_leaves': 21,\n",
    "            'max_bin': 250, \n",
    "            'learning_rate': 0.03,\n",
    "            'feature_fraction': 0.64,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 1,\n",
    "            'verbose': 0,\n",
    "            'n_jobs': 2,\n",
    "        }\n",
    "        x_train, x_test, y_train, y_test = newdf.loc[trtrInd, mainClmns], newdf.loc[trteInd, mainClmns], newdf.loc[trtrInd, 'difScore'], newdf.loc[trteInd, 'difScore']\n",
    "        model = fit_model(params, x_train, x_test, y_train, y_test)\n",
    "\n",
    "        stack1lvl.loc[trteInd, prefix] = np.minimum(16, np.maximum(-16, model.predict(x_test)))\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'l2', 'l1'},\n",
    "        'num_leaves': 21,\n",
    "        'max_bin': 250, \n",
    "        'learning_rate': 0.03,\n",
    "        'feature_fraction': 0.64,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'verbose': 0,\n",
    "        'n_jobs': 2,\n",
    "    }\n",
    "    x_train, x_test, y_train, y_test = newdf.loc[tr_index, mainClmns], newdf.loc[te_index, mainClmns], newdf.loc[tr_index, 'difScore'], newdf.loc[te_index, 'difScore']\n",
    "\n",
    "    model = fit_model(params, x_train, x_test, y_train, y_test)\n",
    "\n",
    "    pred = np.minimum(16, np.maximum(-16, model.predict(x_test)))\n",
    "    stack1lvl.loc[te_index, prefix] = pred\n",
    "    print 'TEST ACCURACY', accuracy_score(pred>0, y_test>0)\n",
    "    gc.collect()\n",
    "    \n",
    "#     if prefix=='HLTV':\n",
    "#         assert False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HLTV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HLTV</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HLTV\n",
       "HLTV   1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack1lvl.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack1lvl.to_csv('./data/stack1lvl.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95044, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack1lvl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'HLTV', u'matchlinkId', u'map', u'teamAId', u'teamBId'], dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack1lvl.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HLTV</th>\n",
       "      <th>matchlinkId</th>\n",
       "      <th>map</th>\n",
       "      <th>teamAId</th>\n",
       "      <th>teamBId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95039</th>\n",
       "      <td>-3.359278</td>\n",
       "      <td>2332007</td>\n",
       "      <td>Inferno</td>\n",
       "      <td>7106</td>\n",
       "      <td>8297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95040</th>\n",
       "      <td>-7.037780</td>\n",
       "      <td>2331877</td>\n",
       "      <td>Nuke</td>\n",
       "      <td>9497</td>\n",
       "      <td>7635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95041</th>\n",
       "      <td>6.978472</td>\n",
       "      <td>2331877</td>\n",
       "      <td>Nuke</td>\n",
       "      <td>7635</td>\n",
       "      <td>9497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95042</th>\n",
       "      <td>-7.673647</td>\n",
       "      <td>2331877</td>\n",
       "      <td>Dust2</td>\n",
       "      <td>9497</td>\n",
       "      <td>7635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95043</th>\n",
       "      <td>7.905405</td>\n",
       "      <td>2331877</td>\n",
       "      <td>Dust2</td>\n",
       "      <td>7635</td>\n",
       "      <td>9497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           HLTV  matchlinkId      map  teamAId  teamBId\n",
       "95039 -3.359278      2332007  Inferno     7106     8297\n",
       "95040 -7.037780      2331877     Nuke     9497     7635\n",
       "95041  6.978472      2331877     Nuke     7635     9497\n",
       "95042 -7.673647      2331877    Dust2     9497     7635\n",
       "95043  7.905405      2331877    Dust2     7635     9497"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack1lvl.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF you have skipped the previous part of this notebook THEN you can stop right here ELSE you can skip this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this part we build the model predicting the map winner for every rating system (as in the previous part, but without time consuming features that almost didn't make any benefit to the model). Also we build the model predicting the probability of winning teamA in a whole match and use it as a feature for predicting the map winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!! PREFIX: HLTV\n",
      "(105604, 99) (105604, 200)\n",
      "187\n",
      "(13445, 295)\n",
      "['teamAavgIncome', 'teamAfirPlaceRatio', 'teamARNOHForce', 'teamA_n_last_maps', 'ratingA_HLTV', 'teamAId', 'teamAkef', 'teamAperMarja', 'teamAper'] ['teamBavgIncome', 'teamBfirPlaceRatio', 'teamBRNOHForce', 'teamB_n_last_maps', 'ratingB_HLTV', 'teamBId', 'teamBkef', 'teamBperMarja', 'teamBper']\n",
      "TRAIN SHAPE: (12265, 23) TEST SHAPE: (3067, 23)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's l2: 0.0191401\tvalid_0's l1: 0.111725\n",
      "[200]\tvalid_0's l2: 0.0181181\tvalid_0's l1: 0.106708\n",
      "[300]\tvalid_0's l2: 0.0178292\tvalid_0's l1: 0.105373\n",
      "[400]\tvalid_0's l2: 0.0177202\tvalid_0's l1: 0.10476\n",
      "[500]\tvalid_0's l2: 0.0176569\tvalid_0's l1: 0.104441\n",
      "Early stopping, best iteration is:\n",
      "[538]\tvalid_0's l2: 0.0176302\tvalid_0's l1: 0.104314\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.087694 MSE: 0.012456\n",
      "TEST MAE: 0.104314 MSE: 0.01763\n",
      "['matchFormat', 'matchType', 'teamAavgIncome', 'teamBavgIncome', 'firPlace', 'maxPrizeUSD', 'teamAfirPlaceRatio', 'teamBfirPlaceRatio', 'teamA_n_last_maps', 'teamB_n_last_maps', 'teamAabsForceProb', 'teamAabsForceHLTVProb', 'ratingA_HLTV', 'ratingB_HLTV']\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's auc: 0.683034\n",
      "[200]\tvalid_0's auc: 0.689668\n",
      "[300]\tvalid_0's auc: 0.691446\n",
      "[400]\tvalid_0's auc: 0.692429\n",
      "[500]\tvalid_0's auc: 0.692933\n",
      "Early stopping, best iteration is:\n",
      "[477]\tvalid_0's auc: 0.692998\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.718551 ACCURACY: 0.658159\n",
      "TEST ROC_AUC: 0.692998 ACCURACY: 0.638921\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's auc: 0.700367\n",
      "[200]\tvalid_0's auc: 0.707164\n",
      "[300]\tvalid_0's auc: 0.709148\n",
      "[400]\tvalid_0's auc: 0.710069\n",
      "Early stopping, best iteration is:\n",
      "[471]\tvalid_0's auc: 0.710404\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.715276 ACCURACY: 0.656103\n",
      "TEST ROC_AUC: 0.710404 ACCURACY: 0.648931\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's auc: 0.710217\n",
      "[200]\tvalid_0's auc: 0.713439\n",
      "[300]\tvalid_0's auc: 0.714413\n",
      "Early stopping, best iteration is:\n",
      "[358]\tvalid_0's auc: 0.714816\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.709777 ACCURACY: 0.653566\n",
      "TEST ROC_AUC: 0.714816 ACCURACY: 0.653139\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's auc: 0.694458\n",
      "[200]\tvalid_0's auc: 0.700856\n",
      "[300]\tvalid_0's auc: 0.703168\n",
      "[400]\tvalid_0's auc: 0.704205\n",
      "[500]\tvalid_0's auc: 0.704929\n",
      "[600]\tvalid_0's auc: 0.705289\n",
      "[700]\tvalid_0's auc: 0.705434\n",
      "[800]\tvalid_0's auc: 0.705692\n",
      "Early stopping, best iteration is:\n",
      "[852]\tvalid_0's auc: 0.705935\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.727428 ACCURACY: 0.665993\n",
      "TEST ROC_AUC: 0.705935 ACCURACY: 0.654401\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's auc: 0.682127\n",
      "[200]\tvalid_0's auc: 0.686414\n",
      "[300]\tvalid_0's auc: 0.688066\n",
      "[400]\tvalid_0's auc: 0.688749\n",
      "[500]\tvalid_0's auc: 0.689246\n",
      "[600]\tvalid_0's auc: 0.689781\n",
      "Early stopping, best iteration is:\n",
      "[587]\tvalid_0's auc: 0.689814\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.722528 ACCURACY: 0.662025\n",
      "TEST ROC_AUC: 0.689814 ACCURACY: 0.637356\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's auc: 0.691443\n",
      "[200]\tvalid_0's auc: 0.694385\n",
      "[300]\tvalid_0's auc: 0.695591\n",
      "[400]\tvalid_0's auc: 0.696111\n",
      "Early stopping, best iteration is:\n",
      "[407]\tvalid_0's auc: 0.696115\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.716249 ACCURACY: 0.6573\n",
      "TEST ROC_AUC: 0.696115 ACCURACY: 0.642406\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's auc: 0.686187\n",
      "[200]\tvalid_0's auc: 0.69208\n",
      "[300]\tvalid_0's auc: 0.694086\n",
      "[400]\tvalid_0's auc: 0.694872\n",
      "[500]\tvalid_0's auc: 0.695396\n",
      "[600]\tvalid_0's auc: 0.695693\n",
      "Early stopping, best iteration is:\n",
      "[607]\tvalid_0's auc: 0.695741\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.718779 ACCURACY: 0.658846\n",
      "TEST ROC_AUC: 0.695741 ACCURACY: 0.641825\n",
      "!!!!!!!!!!! PREFIX: elo0\n",
      "(105604, 99) (105604, 200)\n",
      "187\n",
      "(13445, 295)\n",
      "['teamAavgIncome', 'teamAfirPlaceRatio', 'teamARNOHForce', 'teamA_n_last_maps', 'ratingA_elo0', 'teamAId', 'teamAkef', 'teamAperMarja', 'teamAper'] ['teamBavgIncome', 'teamBfirPlaceRatio', 'teamBRNOHForce', 'teamB_n_last_maps', 'ratingB_elo0', 'teamBId', 'teamBkef', 'teamBperMarja', 'teamBper']\n",
      "TRAIN SHAPE: (12265, 23) TEST SHAPE: (3067, 23)\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's l2: 0.0123666\tvalid_0's l1: 0.0865692\n",
      "[200]\tvalid_0's l2: 0.0115996\tvalid_0's l1: 0.0819752\n",
      "[300]\tvalid_0's l2: 0.0114634\tvalid_0's l1: 0.0810462\n",
      "Early stopping, best iteration is:\n",
      "[284]\tvalid_0's l2: 0.0114555\tvalid_0's l1: 0.0810586\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN MAE: 0.072139 MSE: 0.009143\n",
      "TEST MAE: 0.081059 MSE: 0.011455\n",
      "['matchFormat', 'matchType', 'teamAavgIncome', 'teamBavgIncome', 'firPlace', 'maxPrizeUSD', 'teamAfirPlaceRatio', 'teamBfirPlaceRatio', 'teamA_n_last_maps', 'teamB_n_last_maps', 'teamAabsForceProb', 'teamAabsForceHLTVProb', 'ratingA_elo0', 'ratingB_elo0']\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's auc: 0.691816\n",
      "[200]\tvalid_0's auc: 0.69901\n",
      "[300]\tvalid_0's auc: 0.701478\n",
      "[400]\tvalid_0's auc: 0.702495\n",
      "[500]\tvalid_0's auc: 0.70309\n",
      "[600]\tvalid_0's auc: 0.703276\n",
      "Early stopping, best iteration is:\n",
      "[578]\tvalid_0's auc: 0.703284\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.731778 ACCURACY: 0.668296\n",
      "TEST ROC_AUC: 0.703284 ACCURACY: 0.644152\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's auc: 0.706948\n",
      "[200]\tvalid_0's auc: 0.714374\n",
      "[300]\tvalid_0's auc: 0.716323\n",
      "[400]\tvalid_0's auc: 0.717085\n",
      "Early stopping, best iteration is:\n",
      "[462]\tvalid_0's auc: 0.717449\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.725255 ACCURACY: 0.662704\n",
      "TEST ROC_AUC: 0.717449 ACCURACY: 0.656597\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's auc: 0.722405\n",
      "[200]\tvalid_0's auc: 0.727087\n",
      "[300]\tvalid_0's auc: 0.728671\n",
      "[400]\tvalid_0's auc: 0.729396\n",
      "[500]\tvalid_0's auc: 0.729903\n",
      "Early stopping, best iteration is:\n",
      "[553]\tvalid_0's auc: 0.730174\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.725685 ACCURACY: 0.663234\n",
      "TEST ROC_AUC: 0.730174 ACCURACY: 0.666847\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's auc: 0.704435\n",
      "[200]\tvalid_0's auc: 0.711046\n",
      "[300]\tvalid_0's auc: 0.712694\n",
      "[400]\tvalid_0's auc: 0.713365\n",
      "[500]\tvalid_0's auc: 0.713858\n",
      "Early stopping, best iteration is:\n",
      "[545]\tvalid_0's auc: 0.714079\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.728622 ACCURACY: 0.664641\n",
      "TEST ROC_AUC: 0.714079 ACCURACY: 0.661887\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's auc: 0.692557\n",
      "[200]\tvalid_0's auc: 0.697709\n",
      "[300]\tvalid_0's auc: 0.699132\n",
      "[400]\tvalid_0's auc: 0.69961\n",
      "[500]\tvalid_0's auc: 0.700134\n",
      "[600]\tvalid_0's auc: 0.700566\n",
      "Early stopping, best iteration is:\n",
      "[666]\tvalid_0's auc: 0.70083\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.734448 ACCURACY: 0.671332\n",
      "TEST ROC_AUC: 0.70083 ACCURACY: 0.6443\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's auc: 0.707881\n",
      "[200]\tvalid_0's auc: 0.710527\n",
      "[300]\tvalid_0's auc: 0.711336\n",
      "Early stopping, best iteration is:\n",
      "[350]\tvalid_0's auc: 0.711568\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.723485 ACCURACY: 0.660835\n",
      "TEST ROC_AUC: 0.711568 ACCURACY: 0.656926\n",
      "\n",
      "START FITTING:\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's auc: 0.701285\n",
      "[200]\tvalid_0's auc: 0.707219\n",
      "[300]\tvalid_0's auc: 0.709195\n",
      "[400]\tvalid_0's auc: 0.710122\n",
      "[500]\tvalid_0's auc: 0.710651\n",
      "Early stopping, best iteration is:\n",
      "[522]\tvalid_0's auc: 0.710755\n",
      "FITTING HAS BEEN ENDED\n",
      "\n",
      "VALIDATION:\n",
      "TRAIN ROC_AUC: 0.726197 ACCURACY: 0.664918\n",
      "TEST ROC_AUC: 0.710755 ACCURACY: 0.653784\n",
      "!!!!!!!!!!! PREFIX: elo0Inf\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "File ./rating_systems/elo0Inf/lr_1000_28.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d7a3ab4cfe45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#         continue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# HLTV_lr_1000_28_tDistrNotScaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./rating_systems/%s/lr_1000_28.csv'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mcommonData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/COMMONDATA.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommonData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File ./rating_systems/elo0Inf/lr_1000_28.csv does not exist"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "df = pd.read_csv('./rating_systems/HLTV/lr_1000_28.csv', sep=';')\n",
    "newIndex = np.arange(df.shape[0])\n",
    "newIndex[::2] = df.index.values[:df.shape[0]//2]\n",
    "newIndex[1::2] = df.index.values[df.shape[0]//2:]\n",
    "df.loc[df.index] = df.loc[newIndex].values\n",
    "df = df.iloc[int(df.shape[0]*0.1):]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "stack1lvl = pd.DataFrame(index=df.index)\n",
    "prefixes = [\n",
    "            'HLTV',\n",
    "            'elo0',\n",
    "            'elo0Inf',\n",
    "#             'glicko',\n",
    "#             'glicko2',\n",
    "            'trueskill',\n",
    "            'trueskillUnrate'\n",
    "]\n",
    "\n",
    "for prefix in prefixes:\n",
    "#     if prefix=='HLTV':\n",
    "#         continue\n",
    "        \n",
    "    print '!!!!!!!!!!! PREFIX:', prefix\n",
    "#     if 'glicko' in prefix:\n",
    "#         continue\n",
    "    # HLTV_lr_1000_28_tDistrNotScaled\n",
    "    df = pd.read_csv('./rating_systems/%s/lr_1000_28.csv'%(prefix), sep=';')\n",
    "    commonData = pd.read_csv('./data/COMMONDATA.csv')\n",
    "    print df.shape, commonData.shape\n",
    "\n",
    "    difColumns = list(set(commonData.columns.values) - set(df.columns.values))\n",
    "    # difColumns = list(set(df.columns.values).intersection(set(commonData.columns.values)))\n",
    "    print len(difColumns)\n",
    "\n",
    "    df = pd.merge(df, commonData[difColumns], left_index=True, right_index=True, copy=False)\n",
    "\n",
    "    df['map_str'] = df['map'].values\n",
    "\n",
    "    # map Label encoding\n",
    "    le = LabelEncoder()\n",
    "    df['map'] = le.fit(df['map'].values).transform(df['map'].values)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "#     # Predicting difScore\n",
    "#     # regression\n",
    "    \n",
    "    newdf = df.copy()\n",
    "    newIndex = np.arange(newdf.shape[0])\n",
    "    newIndex[::2] = newdf.index.values[:newdf.shape[0]//2]\n",
    "    newIndex[1::2] = newdf.index.values[newdf.shape[0]//2:]\n",
    "    newdf.loc[newdf.index] = newdf.loc[newIndex].values\n",
    "    newdf = newdf.iloc[int(newdf.shape[0]*0.1):]\n",
    "    newdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#     newdf = newdf.iloc[int(newdf.shape[0]*0.1):]\n",
    "#     newdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    pred_clmns = [\n",
    "    #             'teamAMapLeftToWin', 'teamBMapLeftToWin',\n",
    "                 'matchFormat', 'matchType', 'mapPicker',\n",
    "                'teamAavgIncome', 'teamBavgIncome', \n",
    "                 'firPlace', 'maxPrizeUSD', \n",
    "                'teamAfirPlaceRatio', 'teamBfirPlaceRatio', \n",
    "    #             'teamAmaxPrPoolRatio', 'teamBmaxPrPoolRatio', \n",
    "                 'teamARNOHForce', 'teamBRNOHForce',\n",
    "    #              'teamARNOHForceSpec', 'teamBRNOHForceSpec',\n",
    "\n",
    "                     'teamA_n_last_maps', #'teamA_last_match_passed_days', \n",
    "                     'teamB_n_last_maps', #'teamB_last_match_passed_days', \n",
    "    #                  'teamA_n_last_mapsSpec', #'teamA_last_match_passed_daysSpec', \n",
    "    #                  'teamB_n_last_mapsSpec', #'teamB_last_match_passed_daysSpec', \n",
    "                'teamAabsForceProb', \n",
    "                'teamAabsForceSpecProb', \n",
    "                'teamAabsForceHLTVProb', \n",
    "                'teamAabsForceHLTVSpecProb', \n",
    "                 'teamAabsForceWProb', \n",
    "                 'teamAabsForceSpecWProb', \n",
    "                 'teamAabsForceHLTVWProb', \n",
    "                 'teamAabsForceHLTVSpecWProb', \n",
    "\n",
    "    #             'teamAabsForceW', 'teamAabsForce', \n",
    "    #              'teamAabsForceSpecW', 'teamAabsForceSpec', \n",
    "    #              'teamAabsForceHLTVW', 'teamAabsForceHLTV', \n",
    "    #              'teamAabsForceHLTVSpecW', 'teamAabsForceHLTVSpec', \n",
    "    #             'ratingDif',\n",
    "                 'ratingA_%s'%prefix, 'ratingB_%s'%prefix,\n",
    "    ]\n",
    "    \n",
    "#     cols = pred_clmns\n",
    "#     kefPred = kefPrediction(newdf.copy(), cols)\n",
    "#     newdf['bookPer'] = kefPred.predict(newdf[cols])\n",
    "\n",
    "#     mainClmns = pred_clmns\n",
    "#     mainClmns += ['bookPer']\n",
    "\n",
    "    cols = pred_clmns\n",
    "    kefPred = kefPrediction(newdf.copy(), cols)\n",
    "    cols = [i for i in cols if 'WProb' not in i and 'RNOH' not in i and 'Spec' not in i and 'icker' not in i]\n",
    "    print cols\n",
    "    newdf['bookPer'] = kefPred.predict(newdf[cols])\n",
    "    \n",
    "    mainClmns = pred_clmns\n",
    "    mainClmns += ['bookPer']\n",
    "#     mainClmns += [i for i in newdf.columns if 'fixed' in i] + ['teamAPistolHistoryWin', 'teamAPistolHistoryLoose', 'teamAPistolHistoryWinLooseDif', 'teamAPistolHistoryWinCount', 'teamAPistolHistoryLooseCount', 'teamAPistolHistoryWinCountLooseCountDif']\n",
    "    # mainClmns += ['teamAPistolHistoryWin', 'teamAPistolHistoryLoose']\n",
    "#     print mainClmns\n",
    "\n",
    "#     y_col = 'difScore'\n",
    "#     cond = newdf[y_col]>=-16\n",
    "\n",
    "    tr_index = newdf.iloc[:int(0.7*newdf.shape[0])].index.values\n",
    "    te_index = newdf.iloc[int(0.7*newdf.shape[0]):].index.values\n",
    "#     print tr_index.shape, te_index.shape\n",
    "\n",
    "\n",
    "\n",
    "#     params = {\n",
    "#         'boosting_type': 'gbdt',\n",
    "#         'objective': 'binary',\n",
    "#         'metric': {'l2', 'l1'},\n",
    "#         'num_leaves': 13,\n",
    "#         'max_bin': 150, \n",
    "#         'learning_rate': 0.02,\n",
    "#         'feature_fraction': 0.64,\n",
    "#         'bagging_fraction': 0.8,\n",
    "#         'bagging_freq': 1,\n",
    "#         'verbose': 0,\n",
    "#         'n_jobs': 2,\n",
    "#     }\n",
    "#     x_train, x_test, y_train, y_test = newdf.loc[tr_index, mainClmns], newdf.loc[te_index, mainClmns], (newdf.loc[tr_index, 'difScore']>=0)*1, (newdf.loc[te_index, 'difScore']>=0)*1\n",
    "\n",
    "#     model = fit_model(params, x_train, x_test, y_train, y_test)\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': {'auc'},\n",
    "        'num_leaves': 10,\n",
    "        'max_bin': 100, \n",
    "        'learning_rate': 0.02,\n",
    "        'feature_fraction': 0.64,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'verbose': 0,\n",
    "        'n_jobs': 2,\n",
    "    }\n",
    "    trIndParts = np.array_split(tr_index, 6)\n",
    "    for ind, trteInd in enumerate(trIndParts):\n",
    "        trtrInd = np.concatenate([trIndParts[j] for j in range(len(trIndParts)) if j!=ind])\n",
    "        x_train, x_test, y_train, y_test = newdf.loc[trtrInd, mainClmns], newdf.loc[trteInd, mainClmns], (newdf.loc[trtrInd, 'difScore']>=0)*1, (newdf.loc[trteInd, 'difScore']>=0)*1\n",
    "        model = fit_model(params, x_train, x_test, y_train, y_test)\n",
    "\n",
    "        stack1lvl.loc[trteInd, prefix] = model.predict(x_test)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = newdf.loc[tr_index, mainClmns], newdf.loc[te_index, mainClmns], (newdf.loc[tr_index, 'difScore']>=0)*1, (newdf.loc[te_index, 'difScore']>=0)*1\n",
    "    model = fit_model(params, x_train, x_test, y_train, y_test)\n",
    "    model.save_model('./rating_systems/%s/LGBOutcomeClassifier'%prefix)\n",
    "\n",
    "    stack1lvl.loc[te_index, prefix] = model.predict(x_test)\n",
    "    gc.collect()\n",
    "    \n",
    "#     if prefix=='HLTV':\n",
    "#         assert False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HLTV</th>\n",
       "      <th>elo0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HLTV</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elo0</th>\n",
       "      <td>0.916172</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          HLTV      elo0\n",
       "HLTV  1.000000  0.916172\n",
       "elo0  0.916172  1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack1lvl.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack multiple models in one using simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.read_csv('./rating_systems/elo0/lr_1000_28.csv', sep=';')\n",
    "newIndex = np.arange(newdf.shape[0])\n",
    "newIndex[::2] = newdf.index.values[:newdf.shape[0]//2]\n",
    "newIndex[1::2] = newdf.index.values[newdf.shape[0]//2:]\n",
    "newdf.loc[newdf.index] = newdf.loc[newIndex].values\n",
    "newdf = newdf.iloc[int(newdf.shape[0]*0.1):]\n",
    "newdf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'HLTV', u'elo0'], dtype='object')\n",
      "['HLTV', 'elo0']\n"
     ]
    }
   ],
   "source": [
    "if u'matchlinkId' in stack1lvl.columns:\n",
    "    stack1lvl.drop([u'matchlinkId', u'map',\n",
    "       u'teamAId', u'teamBId'], axis=1, inplace=True)\n",
    "print stack1lvl.columns\n",
    "# linreCmnCols = [i for i in stack1lvl.columns if 'cmn' in i and i not in ['elo0Infcmn', 'glicko2_21cmn', 'elo5Infcmn', 'trueskillcmn', 'trueskillUnratecmn']]# and 'true' not in i and 'glicko' not in i]\n",
    "linreCmnCols = [i for i in stack1lvl.columns]# if 'glicko' not in i and 'Inf' not in i and 'Unrate' not in i and i!='HLTV']# and i not in ['elo5Infcmn', 'elo0Infcmn', 'glicko2_21cmn', 'trueskillcmn', 'trueskillUnratecmn']]\n",
    "#and 'Cat' not in i\n",
    "# linreSpecCols = [i for i in stack1lvl.columns if 'spec' in i]\n",
    "# ['elo0cmn', 'elo0Infcmn', 'elo5cmn', 'elo5Infcmn', 'glicko2_14cmn', 'glicko2_21cmn', 'glicko2_28cmn', 'glicko2_36cmn', 'trueskillcmn', 'trueskillUnratecmn']\n",
    "print(linreCmnCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmn\n",
      "TRAIN accuracy 0.6556891627837066 ROC-AUC 0.7135726152775407\n",
      "TEST accuracy 0.6548362208038156 ROC-AUC 0.7108491823106621\n",
      "[[0.96609153 3.6889013 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xee8ad68>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x298db898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "trIndex = newdf.iloc[:int(newdf.shape[0]*0.7)].index\n",
    "teIndex = newdf.iloc[int(newdf.shape[0]*0.7):].index\n",
    "\n",
    "\n",
    "LogReCmn = LogisticRegression()\n",
    "LogReCmn.fit(stack1lvl.loc[trIndex, linreCmnCols].values, newdf.loc[trIndex, 'difScore'].values>0)\n",
    "joblib.dump(LogReCmn, './models/StackCmnLr_1000_28copy')\n",
    "preTr = LogReCmn.predict_proba(stack1lvl.loc[trIndex, linreCmnCols].values).T[1]\n",
    "preTe = LogReCmn.predict_proba(stack1lvl.loc[teIndex, linreCmnCols].values).T[1]\n",
    "print('cmn')\n",
    "# print(predCmn)\n",
    "# print('MSE', mean_squared_error(predCmn, df.loc[teIndex, 'difScore'].values))\n",
    "# print('MAE', mean_absolute_error(predCmn, df.loc[teIndex, 'difScore'].values))\n",
    "print 'TRAIN accuracy', accuracy_score(newdf.loc[trIndex, 'difScore'].values>0, preTr>0.5), 'ROC-AUC', roc_auc_score(newdf.loc[trIndex, 'difScore'].values>0, preTr)\n",
    "print 'TEST accuracy', accuracy_score(preTe>0.5, newdf.loc[teIndex, 'difScore'].values>0), 'ROC-AUC', roc_auc_score(newdf.loc[teIndex, 'difScore'].values>0, preTe)\n",
    "print LogReCmn.coef_\n",
    "\n",
    "pd.Series(LogReCmn.coef_[0], index=linreCmnCols).plot.bar(width=1, edgecolor='black', figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HLTV</th>\n",
       "      <th>elo0</th>\n",
       "      <th>elo0Inf</th>\n",
       "      <th>glicko</th>\n",
       "      <th>glicko2</th>\n",
       "      <th>trueskill</th>\n",
       "      <th>trueskillUnrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HLTV</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730913</td>\n",
       "      <td>0.739772</td>\n",
       "      <td>0.712364</td>\n",
       "      <td>0.723699</td>\n",
       "      <td>0.719760</td>\n",
       "      <td>0.734808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elo0</th>\n",
       "      <td>0.730913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974444</td>\n",
       "      <td>0.915748</td>\n",
       "      <td>0.934608</td>\n",
       "      <td>0.930412</td>\n",
       "      <td>0.920949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elo0Inf</th>\n",
       "      <td>0.739772</td>\n",
       "      <td>0.974444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925266</td>\n",
       "      <td>0.938839</td>\n",
       "      <td>0.928264</td>\n",
       "      <td>0.925611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glicko</th>\n",
       "      <td>0.712364</td>\n",
       "      <td>0.915748</td>\n",
       "      <td>0.925266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937715</td>\n",
       "      <td>0.925873</td>\n",
       "      <td>0.928741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glicko2</th>\n",
       "      <td>0.723699</td>\n",
       "      <td>0.934608</td>\n",
       "      <td>0.938839</td>\n",
       "      <td>0.937715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940283</td>\n",
       "      <td>0.941124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trueskill</th>\n",
       "      <td>0.719760</td>\n",
       "      <td>0.930412</td>\n",
       "      <td>0.928264</td>\n",
       "      <td>0.925873</td>\n",
       "      <td>0.940283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trueskillUnrate</th>\n",
       "      <td>0.734808</td>\n",
       "      <td>0.920949</td>\n",
       "      <td>0.925611</td>\n",
       "      <td>0.928741</td>\n",
       "      <td>0.941124</td>\n",
       "      <td>0.959739</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     HLTV      elo0   elo0Inf    glicko   glicko2  trueskill  \\\n",
       "HLTV             1.000000  0.730913  0.739772  0.712364  0.723699   0.719760   \n",
       "elo0             0.730913  1.000000  0.974444  0.915748  0.934608   0.930412   \n",
       "elo0Inf          0.739772  0.974444  1.000000  0.925266  0.938839   0.928264   \n",
       "glicko           0.712364  0.915748  0.925266  1.000000  0.937715   0.925873   \n",
       "glicko2          0.723699  0.934608  0.938839  0.937715  1.000000   0.940283   \n",
       "trueskill        0.719760  0.930412  0.928264  0.925873  0.940283   1.000000   \n",
       "trueskillUnrate  0.734808  0.920949  0.925611  0.928741  0.941124   0.959739   \n",
       "\n",
       "                 trueskillUnrate  \n",
       "HLTV                    0.734808  \n",
       "elo0                    0.920949  \n",
       "elo0Inf                 0.925611  \n",
       "glicko                  0.928741  \n",
       "glicko2                 0.941124  \n",
       "trueskill               0.959739  \n",
       "trueskillUnrate         1.000000  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack1lvl.iloc[:, :7].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'map' in stack1lvl.columns.values:\n",
    "    stack1lvl.drop([u'matchlinkId', u'map', u'teamAId', u'teamBId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((95044, 4), (105604, 287), (95044, 2))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = pd.read_csv('./data/matchLinkIds.csv', sep=';')\n",
    "newIndex = np.arange(ids.shape[0])\n",
    "newIndex[::2] = ids.index.values[:ids.shape[0]//2]\n",
    "newIndex[1::2] = ids.index.values[ids.shape[0]//2:]\n",
    "ids.loc[ids.index] = ids.loc[newIndex].values\n",
    "ids.reset_index(drop=True, inplace=True)\n",
    "ids = ids.iloc[int(ids.shape[0]*0.1):]\n",
    "ids.reset_index(drop=True, inplace=True)\n",
    "# ids = ids.iloc[int(ids.shape[0]*0.1):]\n",
    "# ids.reset_index(drop=True, inplace=True)\n",
    "ids.shape, df.shape, stack1lvl.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack1lvl = pd.merge(stack1lvl, ids, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the rest of this notebook we check our model - how much money we can get using this model if we would bet on median of multiple bookmakers coeficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the next cell we define multiple betting strategies and makeBet function. In makeBet function we bet on the result with the probaility >0.5 predicted by our model and bet 500 conventional unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixBet(aKef, bKef, aPer, bPer, aPred, bet, isWin, expWin=0, border=0): #\n",
    "    if aPred>0.5:\n",
    "        if aKef<border:\n",
    "            return 0\n",
    "        if isWin:\n",
    "            return bet*aKef-bet\n",
    "        else:\n",
    "            return -bet\n",
    "    elif aPred<0.5:\n",
    "        if bKef<border:\n",
    "            return 0\n",
    "        if not isWin:\n",
    "            return bet*bKef-bet\n",
    "        else:\n",
    "            return -bet\n",
    "    return 0\n",
    "\n",
    "def flexBet(aKef, bKef, aPer, bPer, aPred, bet, isWin, expWin=0, border=0):\n",
    "    if aPred>0.5:\n",
    "        if aKef<border:\n",
    "            return 0\n",
    "        if expWin:\n",
    "            bet = expWin/max(0.01, (aKef - 1))\n",
    "        if isWin:\n",
    "            return bet*aKef-bet\n",
    "        else:\n",
    "            return -bet\n",
    "    elif aPred<0.5:\n",
    "        if bKef<border:\n",
    "            return 0\n",
    "        if expWin:\n",
    "            bet = expWin/max(0.01, (bKef - 1))\n",
    "        if not isWin:\n",
    "            return bet*bKef-bet\n",
    "        else:\n",
    "            return -bet\n",
    "    return 0\n",
    "\n",
    "def flexBetV2(aKef, bKef, aPer, bPer, aPred, bet, isWin, expWin=0, border=0):\n",
    "    # unused\n",
    "    if aPred>aPer and aPred>0.5:\n",
    "        if isWin:\n",
    "            return bet*aKef-bet\n",
    "        else:\n",
    "            return -bet\n",
    "#     elif aPred<0.5:\n",
    "#         if not isWin:\n",
    "#             return bet*bKef\n",
    "#         else:\n",
    "#             return -bet\n",
    "    return 0\n",
    "\n",
    "def flexBetV31(aKef, bKef, aPer, bPer, aPred, bet, isWin, expWin=0, border=0):\n",
    "    # flexBet but with restrictions\n",
    "    if aPred>0.5:\n",
    "        if aKef<border:\n",
    "            return 0\n",
    "        if expWin:\n",
    "            bet = min(1000, expWin/max(0.01, (aKef - 1)))\n",
    "        if isWin:\n",
    "            return bet*aKef-bet\n",
    "        else:\n",
    "            return -bet\n",
    "    elif aPred<0.5:\n",
    "        if bKef<border:\n",
    "            return 0\n",
    "        if expWin:\n",
    "            bet = min(1000, expWin/max(0.01, (bKef - 1)))\n",
    "        if not isWin:\n",
    "            return bet*bKef-bet\n",
    "        else:\n",
    "            return -bet\n",
    "    return 0\n",
    "\n",
    "def flexBetV4(aKef, bKef, aPer, bPer, aPred, bet, isWin, expWin=0, border=0):\n",
    "    if aPred>0.5:\n",
    "        if aKef<border:\n",
    "            return 0\n",
    "        bet += bet*(aPred-aPer)\n",
    "#         bet = min(1000, bet)\n",
    "#         if expWin:\n",
    "#             bet = max(5000, expWin/max(0.01, (aKef - 1)))\n",
    "        if isWin:\n",
    "            return bet*aKef-bet\n",
    "        else:\n",
    "            return -bet\n",
    "    elif aPred<0.5:\n",
    "        if bKef<border:\n",
    "            return 0\n",
    "        bet += bet*(1-aPred-bPer)\n",
    "#         bet = min(1000, bet)\n",
    "#         if expWin:\n",
    "#             bet = max(5000, expWin/max(0.01, (bKef - 1)))\n",
    "        if not isWin:\n",
    "            return bet*bKef-bet\n",
    "        else:\n",
    "            return -bet\n",
    "    return 0\n",
    "\n",
    "\n",
    "def makeBet(linRe, linreCols, x, betFunc, bet, expWin=0, border=0, bo=0, mode='log'):\n",
    "    tmpIndex = stack1lvl[(stack1lvl['matchlinkId']==x['matchLinkId']) & (stack1lvl['teamAId']==x['teamAId']) & (stack1lvl['teamBId']==x['teamBId'])].index\n",
    "    tmp = stack1lvl.loc[tmpIndex]\n",
    "    if tmp.shape[0] in [1, 3]:\n",
    "        if mode=='reg':\n",
    "            predA = np.maximum(-16, np.minimum(16, linRe.predict(tmp[linreCols].values)))/32.0 + 0.5\n",
    "        elif mode=='log':\n",
    "            predA = linRe.predict_proba(tmp[linreCols].values).T[1]\n",
    "        else:\n",
    "            predA = tmp['HLTV'].values\n",
    "#             print predA, np.maximum(-16, np.minimum(16, linRe.predict(tmp[linreCols].values)))/32.0 + 0.5\n",
    "        if tmp.shape[0]==1 and (tmp.shape[0]==bo or not bo):\n",
    "            totalA = predA[0]\n",
    "            isWin = (newdf.loc[tmpIndex, 'difScore'].values>0).sum()>0\n",
    "        elif tmp.shape[0]<=3 and (tmp.shape[0]==bo or not bo):\n",
    "            isWin = (newdf.loc[tmpIndex, 'difScore'].values>0).sum()>=2\n",
    "            predB = 1 - predA\n",
    "            totalA = predA[0]*predA[1] + predA[0]*(1-predA[1])*predA[2] + (1-predA[0])*predA[1]*predA[2]\n",
    "            totalB = predB[0]*predB[1] + predB[0]*(1-predB[1])*predB[2] + (1-predB[0])*predB[1]*predB[2]\n",
    "#             print(totalA, totalB, totalA+totalB)\n",
    "            if totalA+totalB!=1:\n",
    "                totalA = totalA/(totalA+totalB)\n",
    "                totalB = 1 - totalA\n",
    "            \n",
    "#             ret = betFunc(x['teamAkef'], x['teamBkef'], x['teamAperMarja'], x['teamBperMarja'], totalA, bet, isWin, expWin, border)\n",
    "#             print(df.loc[tmpIndex, 'difScore'].values, (df.loc[tmpIndex, 'difScore'].values>0).sum(), isWin, round(totalA, 4), 'aKef: %s, bKef: %s'%(x['teamAkef'], x['teamBkef']), ret)\n",
    "        else:\n",
    "#             print x.shape, x\n",
    "#             assert False\n",
    "            return 0\n",
    "        ret = betFunc(x['teamAkef'], x['teamBkef'], x['teamAperMarja'], x['teamBperMarja'], totalA, bet, isWin, expWin, border)\n",
    "        return ret\n",
    "#     print tmp.shape\n",
    "#     assert False\n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8168, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7942, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kefs = pd.read_csv('./data/csgoKefs.csv', sep=';')\n",
    "kefs['kefs'] = kefs['kefs'].apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "kefs['teamAkef'] = kefs['kefs'].apply(lambda x: np.median(x.T[0]))#np.median min max np.maximum(1.01, min(x.T[0]))\n",
    "kefs['teamBkef'] = kefs['kefs'].apply(lambda x: np.median(x.T[1]))#np.median min max np.maximum(1.01, min(x.T[1]))\n",
    "kefs['teamAperMarja'] = 1/kefs['teamAkef'].values\n",
    "kefs['teamBperMarja'] = 1/kefs['teamBkef'].values\n",
    "kefs['teamAper'] = kefs['teamAperMarja'].values/(kefs['teamAperMarja'].values + kefs['teamBperMarja'].values)\n",
    "kefs['teamBper'] = kefs['teamBperMarja'].values/(kefs['teamAperMarja'].values + kefs['teamBperMarja'].values)\n",
    "\n",
    "# kefs['teamAkef'] = kefs['kefs'].apply(lambda x: np.min(x.T[0]))\n",
    "# kefs['teamBkef'] = kefs['kefs'].apply(lambda x: np.min(x.T[1]))\n",
    "\n",
    "kefs['teamAkef'] = np.minimum(kefs['teamAkef'].values, [7]*kefs.shape[0])\n",
    "kefs['teamBkef'] = np.minimum(kefs['teamBkef'].values, [7]*kefs.shape[0])\n",
    "kefs.drop_duplicates(['matchLinkId', u'teamAId', u'teamBId'], inplace=True)\n",
    "print kefs.shape\n",
    "j = list(set(kefs[u'matchLinkId'].values) - set(stack1lvl[u'matchlinkId'].values))\n",
    "kefs.drop(kefs[kefs['matchLinkId'].isin(j)].index, inplace=True)\n",
    "kefs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2332013, 2319592)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kefs['matchLinkId'].max(), kefs['matchLinkId'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL MATCHES. Output format - (totalWin, number of wrong predictions, number of right predictions, accuracy, number of predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fixBet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-64455.0, 1257, 2620, 0.6757802424555068, 3877)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO1\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, fixBet, 500, 500, 1, bo=1, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-20667.5, 531, 870, 0.6209850107066381, 1401)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO3\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, fixBet, 500, 500, 1, bo=3, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flexBet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-82620.44019858894, 1257, 2620, 0.6757802424555068, 3877)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO1\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBet, 500, 500, 1, bo=1, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-173811.90740929975, 531, 870, 0.6209850107066381, 1401)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO3\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBet, 500, 500, 1, bo=3, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flexBetV31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-118967.1577116389, 1257, 2620, 0.6757802424555068, 3877)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO1\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBetV31, 500, 500, 1, bo=1, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-9150.161234078176, 531, 870, 0.6209850107066381, 1401)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO3\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBetV4, 500, 500, 1, bo=3, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flexBetV4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-61279.6209916261, 1257, 2620, 0.6757802424555068, 3877)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO1\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBetV4, 500, 500, 1, bo=1, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-9150.161234078176, 531, 870, 0.6209850107066381, 1401)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO3\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBetV4, 500, 500, 1, bo=3, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on matches with bookmakers coef restriction (make a bet on outcome with coef >= 1.7 in a case below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fixBet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3737.5, 419, 396, 0.4858895705521472, 815)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO1\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, fixBet, 500, 500, 1.7, bo=1, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29590.0, 198, 217, 0.5228915662650602, 415)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO3\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, fixBet, 500, 500, 1.7, bo=3, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flexBet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3504.186537803609, 419, 396, 0.4858895705521472, 815)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO1\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBet, 500, 500, 1.7, bo=1, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21716.80184552763, 198, 217, 0.5228915662650602, 415)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO3\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBet, 500, 500, 1.7, bo=3, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flexBetV31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3504.186537803609, 419, 396, 0.4858895705521472, 815)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO1\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBetV31, 500, 500, 1.7, bo=1, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35970.83964239305, 198, 217, 0.5228915662650602, 415)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO3\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBetV4, 500, 500, 1.7, bo=3, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flexBetV4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4859.676766422759, 419, 396, 0.4858895705521472, 815)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO1\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBetV4, 500, 500, 1.7, bo=1, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35970.83964239305, 198, 217, 0.5228915662650602, 415)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logReg all ratingSystems #BO3\n",
    "flexV31 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBetV4, 500, 500, 1.7, bo=3, mode='log'), axis=1)\n",
    "flexV31.sum(), flexV31[flexV31<0].count(), flexV31[flexV31>0].count(), 1-flexV31[flexV31<0].count()/float(flexV31[(flexV31<0) | (flexV31>0)].count()), flexV31[(flexV31<0) | (flexV31>0)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As you can see from results, the model can make us some income with a specific betting restrictions and strategy. Coeficients from multiple bookmakers were parsed for about 1 year period from HLTV within 30 minutes before starting a match. Although you can make a bot making a bet according to this model and get passive income, but for me the risk of getting the ban from bookmakers for auto betting and loosing a lot of money is higher comparing to possible income from the model (before started the project, my expectations about possible income were pretty higher). Also there can be some bugs or leaks in my code and possible income can be actually less comparing to your expectations and my results :) Use it on your own risk!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below you can adjust border parameter to maximaze the possible income during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BORDER 1.0\n",
      "fixBet: -58542.5 flexBet: -76073.92588393358 flexBetV31: -111564.18942657768 flexBetV4: -55791.47015801995 REST: 1250 2627 0.6775857621872582 3877\n",
      "BORDER 1.05\n",
      "fixBet: -59067.5 flexBet: -95407.25921726692 flexBetV31: -112614.18942657768 flexBetV4: -56250.73263626472 REST: 1249 2555 0.6716614090431126 3804\n",
      "BORDER 1.1\n",
      "fixBet: -62050.0 flexBet: -135651.820211828 flexBetV31: -118579.18942657768 flexBetV4: -58914.18996925382 REST: 1243 2384 0.6572925282602702 3627\n",
      "BORDER 1.1500000000000001\n",
      "fixBet: -64820.0 flexBet: -156399.26730635157 flexBetV31: -124119.18942657768 flexBetV4: -61277.79901995962 REST: 1219 2145 0.6376337693222354 3364\n",
      "BORDER 1.2000000000000002\n",
      "fixBet: -63312.5 flexBet: -150211.20467169446 flexBetV31: -121104.18942657768 flexBetV4: -60117.132189835844 REST: 1177 1931 0.6212998712998713 3108\n",
      "BORDER 1.2500000000000002\n",
      "fixBet: -55562.5 flexBet: -115738.67979298113 flexBetV31: -105604.18942657768 flexBetV4: -53190.671315373314 REST: 1116 1735 0.6085584005612066 2851\n",
      "BORDER 1.3000000000000003\n",
      "fixBet: -61420.0 flexBet: -136070.40016822558 flexBetV31: -117319.18942657766 flexBetV4: -58436.30513194397 REST: 1064 1509 0.5864749319860085 2573\n",
      "BORDER 1.3500000000000003\n",
      "fixBet: -49702.5 flexBet: -100788.55859135505 flexBetV31: -93884.18942657768 flexBetV4: -47792.62371488163 REST: 972 1303 0.5727472527472528 2275\n",
      "BORDER 1.4000000000000004\n",
      "fixBet: -40400.0 flexBet: -76717.38638808906 flexBetV31: -75279.18942657766 flexBetV4: -39178.28518600969 REST: 875 1098 0.5565129244804865 1973\n",
      "BORDER 1.4500000000000004\n",
      "fixBet: -36337.5 flexBet: -67428.01100937843 flexBetV31: -67154.18942657768 flexBetV4: -35251.184638351115 REST: 789 918 0.5377855887521968 1707\n",
      "BORDER 1.5000000000000004\n",
      "fixBet: -35890.0 flexBet: -66259.18942657766 flexBetV31: -66259.18942657766 flexBetV4: -35517.20544435274 REST: 705 747 0.5144628099173554 1452\n",
      "BORDER 1.5500000000000005\n",
      "fixBet: -22887.5 flexBet: -41633.087230815705 flexBetV31: -41633.087230815705 flexBetV4: -22635.9074350703 REST: 619 634 0.5059856344772546 1253\n",
      "BORDER 1.6000000000000005\n",
      "fixBet: -12975.0 flexBet: -24567.782626978107 flexBetV31: -24567.782626978107 flexBetV4: -12879.02184066087 REST: 538 529 0.4957825679475164 1067\n",
      "BORDER 1.6500000000000006\n",
      "fixBet: -2567.500000000001 flexBet: -7644.522763230534 flexBetV31: -7644.522763230534 flexBetV4: -2209.627367910535 REST: 463 443 0.48896247240618107 906\n",
      "BORDER 1.7000000000000006\n",
      "fixBet: 9272.5 flexBet: 9858.541911134369 flexBetV31: 9858.541911134369 flexBetV4: 10017.298706298307 REST: 400 385 0.49044585987261147 785\n",
      "BORDER 1.7500000000000007\n",
      "fixBet: 7105.0 flexBet: 6937.49564282129 flexBetV31: 6937.49564282129 flexBetV4: 7485.604854451243 REST: 354 316 0.4716417910447761 670\n",
      "BORDER 1.8000000000000007\n",
      "fixBet: 14555.0 flexBet: 16502.155104044694 flexBetV31: 16502.155104044694 flexBetV4: 15173.811128983474 REST: 321 293 0.4771986970684039 614\n",
      "BORDER 1.8500000000000008\n",
      "fixBet: 10300.0 flexBet: 11368.675733811726 flexBetV31: 11368.675733811726 flexBetV4: 10552.948153303394 REST: 298 255 0.46112115732368897 553\n",
      "BORDER 1.9000000000000008\n",
      "fixBet: 8605.0 flexBet: 9346.501234454105 flexBetV31: 9346.501234454105 flexBetV4: 8718.916207968414 REST: 276 226 0.45019920318725104 502\n",
      "BORDER 1.9500000000000008\n",
      "fixBet: 6022.5 flexBet: 6567.894349755238 flexBetV31: 6567.894349755238 flexBetV4: 6065.776508259547 REST: 256 199 0.43736263736263736 455\n",
      "BORDER 2.000000000000001\n",
      "fixBet: 5702.5 flexBet: 6352.677330435229 flexBetV31: 6352.677330435229 flexBetV4: 5596.668994549878 REST: 230 172 0.427860696517413 402\n",
      "BORDER 2.0500000000000007\n",
      "fixBet: 1415.0 flexBet: 2169.7576556269332 flexBetV31: 2169.7576556269332 flexBetV4: 797.9236764451498 REST: 218 152 0.41081081081081083 370\n"
     ]
    }
   ],
   "source": [
    "#BO1\n",
    "for border in np.arange(1.0, 2.1, .05):\n",
    "    print 'BORDER', border\n",
    "    fixBet123 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, fixBet, 500, 500, border=border, bo=1, mode='log'), axis=1)\n",
    "    flexBet123 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBet, 500, 500, border=border, bo=1, mode='log'), axis=1)\n",
    "    flexBetV31123 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBetV31, 500, 500, border=border, bo=1, mode='log'), axis=1)\n",
    "    flexBetV4123 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBetV4, 500, 500, border=border, bo=1, mode='log'), axis=1)\n",
    "    \n",
    "    print 'fixBet:', fixBet123.sum(), 'flexBet:', flexBet123.sum(), 'flexBetV31:', flexBetV31123.sum(), 'flexBetV4:', flexBetV4123.sum(), 'REST:', flexBetV4123[flexBetV4123<0].count(), flexBetV4123[flexBetV4123>0].count(), 1-flexBetV4123[flexBetV4123<0].count()/float(flexBetV4123[(flexBetV4123<0) | (flexBetV4123>0)].count()), flexBetV4123[(flexBetV4123<0) | (flexBetV4123>0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BORDER 1.0\n",
      "fixBet: -36155.0 flexBet: -192340.93250464858 flexBetV31: -97779.43095039992 flexBetV4: -23649.372255728915 REST: 546 855 0.6102783725910064 1401\n",
      "BORDER 1.05\n",
      "fixBet: -36270.0 flexBet: -196840.93250464858 flexBetV31: -98009.43095039992 flexBetV4: -23753.71538181224 REST: 546 846 0.6077586206896552 1392\n",
      "BORDER 1.1\n",
      "fixBet: -34267.5 flexBet: -171313.15472687082 flexBetV31: -94004.43095039992 flexBetV4: -21942.08393732638 REST: 540 819 0.6026490066225165 1359\n",
      "BORDER 1.1500000000000001\n",
      "fixBet: -31242.5 flexBet: -145287.10670082283 flexBetV31: -87954.43095039992 flexBetV4: -19473.160394075014 REST: 527 765 0.5921052631578947 1292\n",
      "BORDER 1.2000000000000002\n",
      "fixBet: -27077.5 flexBet: -123196.86038418328 flexBetV31: -79624.43095039992 flexBetV4: -15450.04211140489 REST: 509 712 0.5831285831285831 1221\n",
      "BORDER 1.2500000000000002\n",
      "fixBet: -24112.5 flexBet: -109853.75790403069 flexBetV31: -73694.43095039992 flexBetV4: -12792.82327924012 REST: 486 639 0.5680000000000001 1125\n",
      "BORDER 1.3000000000000003\n",
      "fixBet: -12430.0 flexBet: -67459.95397947158 flexBetV31: -50329.430950399925 flexBetV4: -2275.207941901204 REST: 444 573 0.5634218289085546 1017\n",
      "BORDER 1.3500000000000003\n",
      "fixBet: -2552.500000000001 flexBet: -37186.865479330925 flexBetV31: -30574.430950399932 flexBetV4: 7503.319317937312 REST: 408 524 0.5622317596566524 932\n",
      "BORDER 1.4000000000000004\n",
      "fixBet: 4580.0 flexBet: -18640.291335807746 flexBetV31: -16309.430950399932 flexBetV4: 13919.174776373664 REST: 369 459 0.5543478260869565 828\n",
      "BORDER 1.4500000000000004\n",
      "fixBet: 8860.0 flexBet: -8291.410157279883 flexBetV31: -7749.43095039993 flexBetV4: 17316.81287687308 REST: 334 398 0.5437158469945356 732\n",
      "BORDER 1.5000000000000004\n",
      "fixBet: 14062.5 flexBet: 2655.56904960007 flexBetV31: 2655.56904960007 flexBetV4: 22554.27791527374 REST: 298 345 0.536547433903577 643\n",
      "BORDER 1.5500000000000005\n",
      "fixBet: 17577.5 flexBet: 9350.621556251011 flexBetV31: 9350.621556251011 flexBetV4: 25382.39812596125 REST: 267 300 0.5291005291005291 567\n",
      "BORDER 1.6000000000000005\n",
      "fixBet: 17397.5 flexBet: 8822.029981141986 flexBetV31: 8822.029981141986 flexBetV4: 24460.28788046322 REST: 240 253 0.513184584178499 493\n",
      "BORDER 1.6500000000000006\n",
      "fixBet: 17237.5 flexBet: 8670.231779756 flexBetV31: 8670.231779756 flexBetV4: 23796.916449706772 REST: 222 224 0.5022421524663677 446\n",
      "BORDER 1.7000000000000006\n",
      "fixBet: 19607.5 flexBet: 12111.824706045136 flexBetV31: 12111.824706045136 flexBetV4: 26209.33570315955 REST: 201 200 0.49875311720698257 401\n",
      "BORDER 1.7500000000000007\n",
      "fixBet: 14160.0 flexBet: 4626.111898204101 flexBetV31: 4626.111898204101 flexBetV4: 20626.17249074178 REST: 193 174 0.47411444141689374 367\n",
      "BORDER 1.8000000000000007\n",
      "fixBet: 13610.0 flexBet: 3898.366725212162 flexBetV31: 3898.366725212162 flexBetV4: 19109.120282536034 REST: 173 147 0.459375 320\n",
      "BORDER 1.8500000000000008\n",
      "fixBet: 11467.5 flexBet: 1317.3211121726092 flexBetV31: 1317.3211121726092 flexBetV4: 17192.18580217265 REST: 164 131 0.4440677966101695 295\n",
      "BORDER 1.9000000000000008\n",
      "fixBet: 13887.5 flexBet: 4075.544112839724 flexBetV31: 4075.544112839724 flexBetV4: 19922.009168360528 REST: 153 124 0.4476534296028881 277\n",
      "BORDER 1.9500000000000008\n",
      "fixBet: 15625.0 flexBet: 5868.9832401857075 flexBetV31: 5868.9832401857075 flexBetV4: 21729.133734285802 REST: 144 118 0.45038167938931295 262\n",
      "BORDER 2.000000000000001\n",
      "fixBet: 21660.0 flexBet: 12037.474904408009 flexBetV31: 12037.474904408009 flexBetV4: 28276.807674929638 REST: 129 115 0.4713114754098361 244\n",
      "BORDER 2.0500000000000007\n",
      "fixBet: 20505.0 flexBet: 10926.279443836265 flexBetV31: 10926.279443836265 flexBetV4: 26895.58961378441 REST: 120 104 0.4642857142857143 224\n"
     ]
    }
   ],
   "source": [
    "#BO3\n",
    "for border in np.arange(1, 2.1, .05):\n",
    "    print 'BORDER', border\n",
    "    fixBet123 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, fixBet, 500, 500, border=border, bo=3, mode='log'), axis=1)\n",
    "    flexBet123 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBet, 500, 500, border=border, bo=3, mode='log'), axis=1)\n",
    "    flexBetV31123 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBetV31, 500, 500, border=border, bo=3, mode='log'), axis=1)\n",
    "    flexBetV4123 = kefs.apply(lambda x: makeBet(LogReCmn, linreCmnCols, x, flexBetV4, 500, 500, border=border, bo=3, mode='log'), axis=1)\n",
    "    \n",
    "    print 'fixBet:', fixBet123.sum(), 'flexBet:', flexBet123.sum(), 'flexBetV31:', flexBetV31123.sum(), 'flexBetV4:', flexBetV4123.sum(), 'REST:', flexBetV4123[flexBetV4123<0].count(), flexBetV4123[flexBetV4123>0].count(), 1-flexBetV4123[flexBetV4123<0].count()/float(flexBetV4123[(flexBetV4123<0) | (flexBetV4123>0)].count()), flexBetV4123[(flexBetV4123<0) | (flexBetV4123>0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
